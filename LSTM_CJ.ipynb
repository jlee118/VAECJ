{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/justinlee/Desktop/Master/Thesis/venv/lib/python3.7/site-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.utils import to_categorical\n",
    "from tensorflow.keras import layers\n",
    "data = pd.read_csv('data/chicago.csv')\n",
    "\n",
    "# Contextual Activity\n",
    "context_data = data[['Case ID', '(case) customer:age', '(case) customer:currently_student', '(case) customer:household_income',\n",
    "                    '(case) customer:employment_status', '(case) customer:disabled']]\n",
    "\n",
    "# Journey Data\n",
    "all_activities = pd.unique(data['Activity'])\n",
    "activity_encoder = dict(zip(all_activities,range(3,len(all_activities) + 3)))\n",
    "activity_encoder['Start'] = 1\n",
    "activity_encoder['End'] = 2\n",
    "journeys_data = data[['Case ID','Activity']]\n",
    "journeys_data['Activity Label'] = journeys_data['Activity'].apply(lambda x: activity_encoder[x])\n",
    "journeys_data = journeys_data.groupby(['Case ID'])['Activity Label'].apply(list)\n",
    "journeys_data = journeys_data.reset_index(name=\"Activity\")\n",
    "journeys_data['Activity'] = journeys_data['Activity'].apply(lambda x: [1] + x + [2])\n",
    "journey_vecs = keras.preprocessing.sequence.pad_sequences(journeys_data['Activity'], padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = data[['(case) time:DATE_day_of_week_0_is_monday', '(case) customer:employed',\n",
    "               '(case) customer:currently_student', '(case) customer:valid_license']]\n",
    "context = pd.get_dummies(context, columns=['(case) time:DATE_day_of_week_0_is_monday', '(case) customer:employed',\n",
    "                                          '(case) customer:currently_student','(case) customer:valid_license'])\n",
    "context = pd.concat([data['Case ID'], context], axis=1)\n",
    "context.drop_duplicates(subset='Case ID', inplace=True)\n",
    "context.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "id_train, id_test = train_test_split(journeys_data['Case ID'], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Many to one + context\n",
    "def mto_lstm_prep(journey):\n",
    "    inp = [journey[:i] for i in range(1,len(journey))]\n",
    "    out = journey[1:]\n",
    "    return (inp,out)\n",
    "\n",
    "def make_data(id_indexes, journey_df, context_df):\n",
    "    X_j = []\n",
    "    Y = []\n",
    "    X_c = []\n",
    "\n",
    "    selected = journey_df.iloc[id_indexes]\n",
    "\n",
    "    for index, row in selected.iterrows():\n",
    "        inp, out = mto_lstm_prep(row['Activity'])\n",
    "        rep = len(inp)\n",
    "        c = context_df.iloc[index].drop(labels=['index','Case ID']).to_numpy()\n",
    "        c = np.tile(c, (rep, 1))\n",
    "        X_j.extend(inp)\n",
    "        Y.extend(out)\n",
    "        X_c.extend(c)\n",
    "    X_j = keras.preprocessing.sequence.pad_sequences(X_j, padding='pre')\n",
    "    X_c = np.asarray(X_c).astype(\"float32\")\n",
    "    Y = np.asarray(Y).astype(\"float32\")\n",
    "    return (X_j, X_c, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_j_train, X_c_train, Y_train = make_data(id_train.index, journeys_data, context)\n",
    "X_j_test, X_c_test, Y_test = make_data(id_test.index, journeys_data, context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1: 0.46212465260292745\n",
      "accuracy: 0.46550766314826314\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "# For some given group, always take the most popular activity at each time step\n",
    "# Post padding is ok here since we are looking for plain activity indexed by time\n",
    "test_pop = journeys_data['Activity'].iloc[id_test.index]\n",
    "test_pop = keras.preprocessing.sequence.pad_sequences(test_pop, padding='post')\n",
    "\n",
    "# Finding the most popular activities\n",
    "pop_accs = []\n",
    "for i in range(test_pop.shape[1]):\n",
    "    curr_accs = test_pop[:,i]\n",
    "    pop_acc = np.argmax(np.bincount(test_pop[:,i]))\n",
    "    pop_accs.append(pop_acc)\n",
    "    \n",
    "# Finding the correct indices to make baseline Y's\n",
    "indices = np.sum(np.where(X_j_test >= 1, 1, 0), axis=1)\n",
    "Y_baseline = [pop_accs[i] for i in indices]\n",
    "\n",
    "print(\"f1:\", f1_score(Y_test, Y_baseline, average='weighted'))\n",
    "print(\"accuracy:\", accuracy_score(Y_test, Y_baseline))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Many to One LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_38\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_71 (InputLayer)           [(None, 18)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_70 (InputLayer)           [(None, 16, 1)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_94 (Dense)                (None, 3)            57          input_71[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_20 (LSTM)                  (None, 128)          66560       input_70[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_29 (Concatenate)    (None, 131)          0           dense_94[0][0]                   \n",
      "                                                                 lstm_20[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_95 (Dense)                (None, 18)           2376        concatenate_29[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 68,993\n",
      "Trainable params: 68,993\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lstm_dim = 128\n",
    "timesteps = X_j_train.shape[1]\n",
    "context_dim = X_c_train.shape[1]\n",
    "output_dim = len(activity_encoder) + 1\n",
    "\n",
    "input_journey = layers.Input(shape=(timesteps, 1))\n",
    "input_context = layers.Input(shape=(context_dim,))\n",
    "\n",
    "lstm = layers.LSTM(lstm_dim, recurrent_dropout=0.5)(input_journey)\n",
    "dense = layers.Dense(3, activation=\"relu\")(input_context)\n",
    "merged = layers.Concatenate()([dense, lstm])\n",
    "softmax = layers.Dense(output_dim, activation=\"softmax\")(merged)\n",
    "model = keras.Model([input_journey, input_context], softmax)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n",
      "3063/3063 [==============================] - 40s 13ms/step - loss: 1.3490 - val_loss: 1.0896\n",
      "Epoch 2/75\n",
      "3063/3063 [==============================] - 40s 13ms/step - loss: 1.0833 - val_loss: 1.0595\n",
      "Epoch 3/75\n",
      "3063/3063 [==============================] - 40s 13ms/step - loss: 1.0531 - val_loss: 1.0457\n",
      "Epoch 4/75\n",
      "3063/3063 [==============================] - 41s 13ms/step - loss: 1.0392 - val_loss: 1.0391\n",
      "Epoch 5/75\n",
      "3063/3063 [==============================] - 41s 13ms/step - loss: 1.0381 - val_loss: 1.0313\n",
      "Epoch 6/75\n",
      "3063/3063 [==============================] - 42s 14ms/step - loss: 1.0346 - val_loss: 1.0284\n",
      "Epoch 7/75\n",
      "3063/3063 [==============================] - 41s 13ms/step - loss: 1.0220 - val_loss: 1.0256\n",
      "Epoch 8/75\n",
      "3063/3063 [==============================] - 42s 14ms/step - loss: 1.0158 - val_loss: 1.0236\n",
      "Epoch 9/75\n",
      "3063/3063 [==============================] - 41s 13ms/step - loss: 1.0201 - val_loss: 1.0193\n",
      "Epoch 10/75\n",
      "3063/3063 [==============================] - 42s 14ms/step - loss: 1.0138 - val_loss: 1.0189\n",
      "Epoch 11/75\n",
      "3063/3063 [==============================] - 41s 13ms/step - loss: 1.0248 - val_loss: 1.0174\n",
      "Epoch 12/75\n",
      "3063/3063 [==============================] - 42s 14ms/step - loss: 1.0201 - val_loss: 1.0173\n",
      "Epoch 13/75\n",
      "3063/3063 [==============================] - 42s 14ms/step - loss: 1.0121 - val_loss: 1.0171\n",
      "Epoch 14/75\n",
      "3063/3063 [==============================] - 42s 14ms/step - loss: 1.0123 - val_loss: 1.0192\n",
      "Epoch 15/75\n",
      "3063/3063 [==============================] - 42s 14ms/step - loss: 1.0057 - val_loss: 1.0138\n",
      "Epoch 16/75\n",
      "3063/3063 [==============================] - 42s 14ms/step - loss: 0.9956 - val_loss: 1.0147\n",
      "Epoch 17/75\n",
      "3063/3063 [==============================] - 42s 14ms/step - loss: 1.0140 - val_loss: 1.0145\n",
      "Epoch 18/75\n",
      "3063/3063 [==============================] - 42s 14ms/step - loss: 1.0124 - val_loss: 1.0112\n",
      "Epoch 19/75\n",
      "3063/3063 [==============================] - 42s 14ms/step - loss: 1.0040 - val_loss: 1.0148\n",
      "Epoch 20/75\n",
      "3063/3063 [==============================] - 42s 14ms/step - loss: 1.0000 - val_loss: 1.0135\n",
      "Epoch 21/75\n",
      "3063/3063 [==============================] - 42s 14ms/step - loss: 1.0031 - val_loss: 1.0121\n",
      "Epoch 22/75\n",
      "3063/3063 [==============================] - 42s 14ms/step - loss: 1.0084 - val_loss: 1.0115\n",
      "Epoch 23/75\n",
      "3063/3063 [==============================] - 42s 14ms/step - loss: 0.9965 - val_loss: 1.0110\n",
      "Epoch 24/75\n",
      "3063/3063 [==============================] - 42s 14ms/step - loss: 0.9944 - val_loss: 1.0132\n",
      "Epoch 25/75\n",
      "3063/3063 [==============================] - 42s 14ms/step - loss: 1.0001 - val_loss: 1.0106\n",
      "Epoch 26/75\n",
      "3063/3063 [==============================] - 42s 14ms/step - loss: 1.0036 - val_loss: 1.0095\n",
      "Epoch 27/75\n",
      "3063/3063 [==============================] - 42s 14ms/step - loss: 0.9995 - val_loss: 1.0135\n",
      "Epoch 28/75\n",
      "3063/3063 [==============================] - 41s 13ms/step - loss: 0.9996 - val_loss: 1.0110\n",
      "Epoch 29/75\n",
      "3063/3063 [==============================] - 41s 13ms/step - loss: 1.0031 - val_loss: 1.0094\n",
      "Epoch 30/75\n",
      "3063/3063 [==============================] - 41s 13ms/step - loss: 1.0023 - val_loss: 1.0106\n",
      "Epoch 31/75\n",
      "3063/3063 [==============================] - 41s 13ms/step - loss: 0.9995 - val_loss: 1.0096\n",
      "Epoch 32/75\n",
      "3063/3063 [==============================] - 41s 13ms/step - loss: 1.0020 - val_loss: 1.0093\n",
      "Epoch 33/75\n",
      "3063/3063 [==============================] - 41s 13ms/step - loss: 0.9972 - val_loss: 1.0088\n",
      "Epoch 34/75\n",
      "3063/3063 [==============================] - 41s 14ms/step - loss: 0.9989 - val_loss: 1.0098\n",
      "Epoch 35/75\n",
      "3063/3063 [==============================] - 44s 14ms/step - loss: 1.0002 - val_loss: 1.0083\n",
      "Epoch 36/75\n",
      "3063/3063 [==============================] - 44s 14ms/step - loss: 1.0041 - val_loss: 1.0125\n",
      "Epoch 37/75\n",
      "3063/3063 [==============================] - 42s 14ms/step - loss: 0.9951 - val_loss: 1.0078\n",
      "Epoch 38/75\n",
      "3063/3063 [==============================] - 41s 13ms/step - loss: 0.9928 - val_loss: 1.0068\n",
      "Epoch 39/75\n",
      "3063/3063 [==============================] - 41s 13ms/step - loss: 0.9983 - val_loss: 1.0076\n",
      "Epoch 40/75\n",
      "3063/3063 [==============================] - 41s 13ms/step - loss: 0.9989 - val_loss: 1.0070\n",
      "Epoch 41/75\n",
      "3063/3063 [==============================] - 41s 14ms/step - loss: 1.0016 - val_loss: 1.0099\n",
      "Epoch 42/75\n",
      "3063/3063 [==============================] - 42s 14ms/step - loss: 0.9982 - val_loss: 1.0087\n",
      "Epoch 43/75\n",
      "3063/3063 [==============================] - 42s 14ms/step - loss: 1.0004 - val_loss: 1.0078\n",
      "Epoch 44/75\n",
      "3063/3063 [==============================] - 41s 14ms/step - loss: 1.0089 - val_loss: 1.0079\n",
      "Epoch 45/75\n",
      "3063/3063 [==============================] - 42s 14ms/step - loss: 1.0062 - val_loss: 1.0064\n",
      "Epoch 46/75\n",
      "3063/3063 [==============================] - 41s 13ms/step - loss: 0.9958 - val_loss: 1.0071\n",
      "Epoch 47/75\n",
      "3063/3063 [==============================] - 41s 13ms/step - loss: 0.9931 - val_loss: 1.0077\n",
      "Epoch 48/75\n",
      "3063/3063 [==============================] - 42s 14ms/step - loss: 0.9919 - val_loss: 1.0076\n",
      "Epoch 49/75\n",
      "3063/3063 [==============================] - 41s 13ms/step - loss: 0.9936 - val_loss: 1.0062\n",
      "Epoch 50/75\n",
      "3063/3063 [==============================] - 41s 13ms/step - loss: 0.9877 - val_loss: 1.0072\n",
      "Epoch 51/75\n",
      "3063/3063 [==============================] - 42s 14ms/step - loss: 0.9973 - val_loss: 1.0055\n",
      "Epoch 52/75\n",
      "3063/3063 [==============================] - 41s 13ms/step - loss: 0.9957 - val_loss: 1.0077\n",
      "Epoch 53/75\n",
      "3063/3063 [==============================] - 41s 13ms/step - loss: 1.0004 - val_loss: 1.0082\n",
      "Epoch 54/75\n",
      "3063/3063 [==============================] - 41s 14ms/step - loss: 0.9858 - val_loss: 1.0059\n",
      "Epoch 55/75\n",
      "3063/3063 [==============================] - 41s 13ms/step - loss: 0.9898 - val_loss: 1.0056\n",
      "Epoch 56/75\n",
      "3063/3063 [==============================] - 41s 13ms/step - loss: 0.9919 - val_loss: 1.0066\n",
      "Epoch 57/75\n",
      "3063/3063 [==============================] - 41s 14ms/step - loss: 0.9992 - val_loss: 1.0053\n",
      "Epoch 58/75\n",
      "3063/3063 [==============================] - 40s 13ms/step - loss: 0.9978 - val_loss: 1.0047\n",
      "Epoch 59/75\n",
      "3063/3063 [==============================] - 41s 13ms/step - loss: 0.9895 - val_loss: 1.0044\n",
      "Epoch 60/75\n",
      "3063/3063 [==============================] - 41s 13ms/step - loss: 0.9940 - val_loss: 1.0048\n",
      "Epoch 61/75\n",
      "3063/3063 [==============================] - 41s 13ms/step - loss: 0.9937 - val_loss: 1.0055\n",
      "Epoch 62/75\n",
      "3063/3063 [==============================] - 41s 14ms/step - loss: 0.9935 - val_loss: 1.0055\n",
      "Epoch 63/75\n",
      "3063/3063 [==============================] - 40s 13ms/step - loss: 0.9969 - val_loss: 1.0060\n",
      "Epoch 64/75\n",
      "3063/3063 [==============================] - 41s 14ms/step - loss: 0.9954 - val_loss: 1.0050\n",
      "Epoch 65/75\n",
      "3063/3063 [==============================] - 41s 13ms/step - loss: 0.9857 - val_loss: 1.0055\n",
      "Epoch 66/75\n",
      "3063/3063 [==============================] - 42s 14ms/step - loss: 0.9913 - val_loss: 1.0060\n",
      "Epoch 67/75\n",
      "3063/3063 [==============================] - 40s 13ms/step - loss: 0.9858 - val_loss: 1.0055\n",
      "Epoch 68/75\n",
      "3063/3063 [==============================] - 41s 13ms/step - loss: 0.9993 - val_loss: 1.0061\n",
      "Epoch 69/75\n",
      "3063/3063 [==============================] - 40s 13ms/step - loss: 0.9959 - val_loss: 1.0062\n",
      "Epoch 70/75\n",
      "3063/3063 [==============================] - 41s 13ms/step - loss: 0.9929 - val_loss: 1.0047\n",
      "Epoch 71/75\n",
      "3063/3063 [==============================] - 40s 13ms/step - loss: 0.9927 - val_loss: 1.0042\n",
      "Epoch 72/75\n",
      "3063/3063 [==============================] - 40s 13ms/step - loss: 0.9827 - val_loss: 1.0044\n",
      "Epoch 73/75\n",
      "3063/3063 [==============================] - 41s 13ms/step - loss: 0.9957 - val_loss: 1.0047\n",
      "Epoch 74/75\n",
      "3063/3063 [==============================] - 40s 13ms/step - loss: 0.9920 - val_loss: 1.0034\n",
      "Epoch 75/75\n",
      "3063/3063 [==============================] - 41s 13ms/step - loss: 0.9847 - val_loss: 1.0043\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "opt = keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=opt, loss='sparse_categorical_crossentropy')\n",
    "callback = keras.callbacks.EarlyStopping(monitor='loss', patience=5)\n",
    "history = model.fit([X_j_train, X_c_train], Y_train, validation_split=0.2, batch_size=32, epochs=75, callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x182d15790>"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.legend(['train', 'val'], loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict([X_j_test, X_c_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30755, 18)"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_c_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs = np.argmax(preds, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1: 0.6631600991204788\n",
      "accuracy: 0.734742318322224\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "print(\"f1:\", f1_score(Y_test, accs, average='weighted'))\n",
    "print(\"accuracy:\", accuracy_score(Y_test, accs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Conditional Journeys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "activity_decoder = {j:i for i,j in activity_encoder.items()}\n",
    "def sample_activity(probs, mode=\"max\"):\n",
    "    if mode == \"max\":\n",
    "        return np.argmax(probs)\n",
    "    elif mode ==\"multi\":\n",
    "        return np.argmax(np.random.multinomial(1, probs))\n",
    "    else:\n",
    "        return\n",
    "        \n",
    "def generate(context, model, decode=\"off\"):\n",
    "    seed = [1]\n",
    "    context = context.reshape(1,context.shape[0])\n",
    "    for i in range(16):\n",
    "        seed_padded = keras.preprocessing.sequence.pad_sequences([seed], maxlen=16, padding='pre')\n",
    "        probs = model.predict([seed_padded, context])[0]\n",
    "        probs = np.asarray(probs).astype('float64')\n",
    "        probs = probs / np.sum(probs)\n",
    "        activity = sample_activity(probs, mode=\"multi\")\n",
    "        seed.append(activity)\n",
    "    if decode == \"on\":\n",
    "        seed = [activity_decoder[s] for s in seed]\n",
    "    return seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Start',\n",
       " 'All other home activities',\n",
       " 'Recreation/Entertainment',\n",
       " 'All other home activities',\n",
       " 'End',\n",
       " 'End',\n",
       " 'Picked up passenger',\n",
       " 'All other home activities',\n",
       " 'End',\n",
       " 'End',\n",
       " 'End',\n",
       " 'End',\n",
       " 'End',\n",
       " 'End',\n",
       " 'End',\n",
       " 'End',\n",
       " 'End']"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_c_test_ = context.iloc[id_test.index]\n",
    "X_j_test_ = journeys_data.iloc[id_test.index]\n",
    "sample_c = X_c_test.iloc[12].drop(labels=['index', 'Case ID']).to_numpy().astype(\"float32\")\n",
    "generate(sample_c, model, decode=\"on\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Start',\n",
       " 'All other home activities',\n",
       " 'Recreation/Entertainment',\n",
       " 'Eat meal outside of home',\n",
       " 'All other home activities',\n",
       " 'End']"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[activity_decoder[i] for i in X_j_test_.iloc[12]['Activity']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conditional Temporal VAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_34\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_64 (InputLayer)           [(None, 18)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_63 (InputLayer)           [(None, 16, 1)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_84 (Dense)                (None, 3)            57          input_64[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_18 (LSTM)                  (None, 128)          66560       input_63[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_26 (Concatenate)    (None, 131)          0           dense_84[0][0]                   \n",
      "                                                                 lstm_18[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_88 (Dense)                (None, 3)            396         concatenate_26[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 3)            12          dense_88[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_89 (Dense)                (None, 3)            396         concatenate_26[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_85 (Dense)                (None, 3)            57          input_64[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "sample_16 (Sample)              (None, 3)            0           batch_normalization_8[0][0]      \n",
      "                                                                 dense_89[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_86 (Dense)                (None, 3)            396         concatenate_26[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_87 (Dense)                (None, 3)            396         concatenate_26[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "sample_17 (Sample)              (None, 3)            0           dense_84[0][0]                   \n",
      "                                                                 dense_85[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 68,270\n",
      "Trainable params: 68,264\n",
      "Non-trainable params: 6\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lstm_dim = 128\n",
    "latent_dim = 3\n",
    "c_dim = 3\n",
    "batch_size = 16\n",
    "timesteps = X_j_train.shape[1]\n",
    "context_dim = X_c_train.shape[1]\n",
    "output_dim = len(activity_encoder) + 1\n",
    "\n",
    "\n",
    "class Sample(layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "input_j = layers.Input(shape=(timesteps, 1))\n",
    "input_c = layers.Input(shape=(context_dim))\n",
    "\n",
    "lstm = layers.LSTM(lstm_dim)(input_j)\n",
    "\n",
    "c_pos_mean = layers.Dense(latent_dim)(input_c)\n",
    "c_pos_log_var = layers.Dense(latent_dim)(input_c)\n",
    "\n",
    "c_concat = layers.Concatenate()([c_pos_mean, lstm])\n",
    "prior_mean_linear = layers.Dense(latent_dim)(c_concat)\n",
    "prior_log_var = layers.Dense(latent_dim)(c_concat)\n",
    "\n",
    "pos_mean_linear = layers.Dense(latent_dim)(c_concat)\n",
    "pos_mean = layers.BatchNormalization()(pos_mean_linear)\n",
    "pos_log_var = layers.Dense(latent_dim)(c_concat)\n",
    "\n",
    "z_pos = Sample()([pos_mean, pos_log_var])\n",
    "z_cpos = Sample()([c_pos_mean, c_pos_log_var])\n",
    "\n",
    "encoder = keras.Model([input_j, input_c],\n",
    "                      [z_pos, pos_mean, pos_log_var, \n",
    "                       prior_mean_linear, prior_log_var,\n",
    "                       z_cpos, c_pos_mean, c_pos_log_var])\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Varying Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_35\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_65 (InputLayer)           [(None, 3)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_90 (Dense)                (None, 18)           72          input_65[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_66 (InputLayer)           [(None, 3)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)            (None, 18)           0           dense_90[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 72\n",
      "Trainable params: 72\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_z = layers.Input(shape=(latent_dim,))\n",
    "input_c_z = layers.Input(shape=(latent_dim,))\n",
    "merge = layers.Concatenate()([input_z, input_c_z])\n",
    "output = layers.Dense(output_dim, activation=\"softmax\")(input_z)\n",
    "output = layers.Dropout(0.5)(output)\n",
    "decoder = keras.Model([input_z, input_c_z], output)\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Context Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_36\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_67 (InputLayer)        [(None, 3)]               0         \n",
      "_________________________________________________________________\n",
      "dense_91 (Dense)             (None, 18)                72        \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 18)                0         \n",
      "=================================================================\n",
      "Total params: 72\n",
      "Trainable params: 72\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_c_z = layers.Input(shape=(latent_dim,))\n",
    "output = layers.Dense(context_dim, activation=\"softmax\")(input_c_z)\n",
    "output = layers.Dropout(0.5)(output)\n",
    "context_decoder = keras.Model(input_c_z, output)\n",
    "context_decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "from keras.callbacks import Callback\n",
    "\n",
    "def custom_KL(posterior_means, prior_means, posterior_log_var, prior_log_var):\n",
    "    # KL of p under q    \n",
    "    kl = prior_log_var - posterior_log_var + (tf.exp(posterior_log_var) + \n",
    "                                       tf.square(posterior_means - prior_means)) / tf.exp(prior_log_var) - 1\n",
    "    kl = 0.5 * tf.reduce_sum(kl, axis=1)\n",
    "    return kl\n",
    "\n",
    "# total number of epochs\n",
    "n_epochs = 75\n",
    "# The number of epochs at which KL loss should be included\n",
    "klstart = 15\n",
    "# number of epochs over which KL scaling is increased from 0 to 1\n",
    "kl_annealtime = 10\n",
    "\n",
    "class AnnealingCallback(Callback):\n",
    "    def __init__(self, weight):\n",
    "        self.weight = weight\n",
    "    def on_epoch_end (self, epoch, logs={}):\n",
    "        if epoch > klstart :\n",
    "            new_weight = min(K.get_value(self.weight) + (1./ kl_annealtime), 1.)\n",
    "            K.set_value(self.weight, new_weight)\n",
    "        print (\"Current KL Weight is \" + str(K.get_value(self.weight)))\n",
    "\n",
    "class RVAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder, c_decoder,**kwargs):\n",
    "        super(RVAE, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.c_decoder = c_decoder\n",
    "    def compile(self, optimizer, beta):\n",
    "        super(RVAE, self).compile()\n",
    "        self.optimizer = optimizer\n",
    "        self.beta = beta\n",
    "        \n",
    "    def train_step(self,data):\n",
    "        if isinstance(data, tuple):\n",
    "            journeys, contexts = data[0]\n",
    "            output = data[1]\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            z, pos_means, pos_log_var, prior_means, \\\n",
    "            prior_log_var, z_cpos, c_pos_means, c_pos_log_var= self.encoder([journeys, contexts])\n",
    "            pred_activity = self.decoder([z, z_cpos])\n",
    "            pred_context = self.c_decoder(z_cpos)\n",
    "            \n",
    "            journey_loss = tf.reduce_mean(\n",
    "                tf.reduce_sum(tf.keras.losses.sparse_categorical_crossentropy(output, pred_activity))\n",
    "            )\n",
    "                        \n",
    "            t_kl_divergence =   tf.reduce_mean(\n",
    "                custom_KL(pos_means, prior_means, pos_log_var, prior_log_var)\n",
    "            )\n",
    "            \n",
    "            c_kl_divergence = tf.reduce_mean(\n",
    "                custom_KL(c_pos_means, prior_means, c_pos_log_var, prior_log_var)\n",
    "            )\n",
    "            \n",
    "            context_loss = tf.reduce_mean(\n",
    "                tf.keras.losses.binary_crossentropy(contexts, pred_context)\n",
    "            )\n",
    "\n",
    "            total_loss = journey_loss + context_loss + self.beta * (t_kl_divergence + c_kl_divergence)\n",
    "\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        return {\n",
    "            \"loss\": total_loss,\n",
    "            \"journey_loss\":journey_loss,\n",
    "            \"t_kl_divergence\": t_kl_divergence,\n",
    "            \"c_divergence\": c_kl_divergence,\n",
    "        }\n",
    "     \n",
    "    def test_step(self, data):\n",
    "        journeys, contexts = data[0]\n",
    "        outputs = data[1]\n",
    "        pred_activity, pred_context = self([journeys, contexts], training=False)\n",
    "        journey_loss = tf.keras.losses.sparse_categorical_crossentropy(outputs, pred_activity)\n",
    "        context_loss = tf.keras.losses.binary_crossentropy(contexts, pred_context)\n",
    "        return {\n",
    "            \"journey_loss\": journey_loss,\n",
    "            \"context_loss\": context_loss\n",
    "        }\n",
    "            \n",
    "    def call(self, data):\n",
    "        journeys, contexts = data\n",
    "        z, pos_means, pos_log_var, prior_means, \\\n",
    "        prior_log_var, z_cpos, c_pos_means, c_pos_log_var= self.encoder([journeys, contexts])\n",
    "        return(self.decoder([z, z_cpos]), self.c_decoder(z_cpos))\n",
    "    \n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n",
      "3063/3063 [==============================] - 25s 8ms/step - loss: 60.3232 - journey_loss: 59.6421 - t_kl_divergence: 56.9470 - c_divergence: 3.1600 - val_journey_loss: 1.3110 - val_context_loss: 0.6203\n",
      "Current KL Weight is 0.0\n",
      "Epoch 2/75\n",
      "3063/3063 [==============================] - 24s 8ms/step - loss: 43.7477 - journey_loss: 43.1555 - t_kl_divergence: 64.2409 - c_divergence: 2.7830 - val_journey_loss: 1.0812 - val_context_loss: 0.5575\n",
      "Current KL Weight is 0.0\n",
      "Epoch 3/75\n",
      "3063/3063 [==============================] - 25s 8ms/step - loss: 40.6797 - journey_loss: 40.1439 - t_kl_divergence: 59.7025 - c_divergence: 4.0805 - val_journey_loss: 1.0322 - val_context_loss: 0.5165\n",
      "Current KL Weight is 0.0\n",
      "Epoch 4/75\n",
      "3063/3063 [==============================] - 24s 8ms/step - loss: 39.5191 - journey_loss: 39.0129 - t_kl_divergence: 62.3216 - c_divergence: 6.1994 - val_journey_loss: 1.0326 - val_context_loss: 0.4927\n",
      "Current KL Weight is 0.0\n",
      "Epoch 5/75\n",
      "3063/3063 [==============================] - 22s 7ms/step - loss: 38.6631 - journey_loss: 38.1748 - t_kl_divergence: 63.8633 - c_divergence: 8.4150 - val_journey_loss: 0.9928 - val_context_loss: 0.4810\n",
      "Current KL Weight is 0.0\n",
      "Epoch 6/75\n",
      "3063/3063 [==============================] - 22s 7ms/step - loss: 37.8412 - journey_loss: 37.3646 - t_kl_divergence: 66.0059 - c_divergence: 10.7213 - val_journey_loss: 0.9381 - val_context_loss: 0.4755\n",
      "Current KL Weight is 0.0\n",
      "Epoch 7/75\n",
      "3063/3063 [==============================] - 22s 7ms/step - loss: 37.1223 - journey_loss: 36.6526 - t_kl_divergence: 69.0466 - c_divergence: 13.1048 - val_journey_loss: 0.9142 - val_context_loss: 0.4748\n",
      "Current KL Weight is 0.0\n",
      "Epoch 8/75\n",
      "3063/3063 [==============================] - 23s 7ms/step - loss: 36.5656 - journey_loss: 36.1000 - t_kl_divergence: 69.8036 - c_divergence: 15.0792 - val_journey_loss: 0.9066 - val_context_loss: 0.4702\n",
      "Current KL Weight is 0.0\n",
      "Epoch 9/75\n",
      "3063/3063 [==============================] - 23s 7ms/step - loss: 36.1736 - journey_loss: 35.7107 - t_kl_divergence: 69.7318 - c_divergence: 16.6915 - val_journey_loss: 0.8507 - val_context_loss: 0.4681\n",
      "Current KL Weight is 0.0\n",
      "Epoch 10/75\n",
      "3063/3063 [==============================] - 22s 7ms/step - loss: 35.8861 - journey_loss: 35.4252 - t_kl_divergence: 69.5954 - c_divergence: 18.0917 - val_journey_loss: 0.8469 - val_context_loss: 0.4662\n",
      "Current KL Weight is 0.0\n",
      "Epoch 11/75\n",
      "3063/3063 [==============================] - 23s 7ms/step - loss: 35.6495 - journey_loss: 35.1902 - t_kl_divergence: 68.3588 - c_divergence: 19.2284 - val_journey_loss: 0.8275 - val_context_loss: 0.4650\n",
      "Current KL Weight is 0.0\n",
      "Epoch 12/75\n",
      "3063/3063 [==============================] - 24s 8ms/step - loss: 35.4658 - journey_loss: 35.0077 - t_kl_divergence: 67.3973 - c_divergence: 19.9804 - val_journey_loss: 0.8233 - val_context_loss: 0.4640\n",
      "Current KL Weight is 0.0\n",
      "Epoch 13/75\n",
      "3063/3063 [==============================] - 23s 7ms/step - loss: 35.3153 - journey_loss: 34.8583 - t_kl_divergence: 67.6680 - c_divergence: 20.7717 - val_journey_loss: 0.8259 - val_context_loss: 0.4629\n",
      "Current KL Weight is 0.0\n",
      "Epoch 14/75\n",
      "3063/3063 [==============================] - 23s 7ms/step - loss: 35.1967 - journey_loss: 34.7405 - t_kl_divergence: 67.3726 - c_divergence: 21.3394 - val_journey_loss: 0.8229 - val_context_loss: 0.4627\n",
      "Current KL Weight is 0.0\n",
      "Epoch 15/75\n",
      "3063/3063 [==============================] - 25s 8ms/step - loss: 35.1129 - journey_loss: 34.6574 - t_kl_divergence: 68.0531 - c_divergence: 21.9860 - val_journey_loss: 0.8147 - val_context_loss: 0.4622\n",
      "Current KL Weight is 0.0\n",
      "Epoch 16/75\n",
      "3063/3063 [==============================] - 25s 8ms/step - loss: 35.0205 - journey_loss: 34.5656 - t_kl_divergence: 68.1983 - c_divergence: 22.5992 - val_journey_loss: 0.8296 - val_context_loss: 0.4611\n",
      "Current KL Weight is 0.0\n",
      "Epoch 17/75\n",
      "3063/3063 [==============================] - 25s 8ms/step - loss: 34.9440 - journey_loss: 34.4897 - t_kl_divergence: 70.4619 - c_divergence: 23.2005 - val_journey_loss: 0.8042 - val_context_loss: 0.4604\n",
      "Current KL Weight is 0.1\n",
      "Epoch 18/75\n",
      "3063/3063 [==============================] - 27s 9ms/step - loss: 37.2193 - journey_loss: 34.5669 - t_kl_divergence: 7.6004 - c_divergence: 14.3837 - val_journey_loss: 0.8390 - val_context_loss: 0.4598\n",
      "Current KL Weight is 0.2\n",
      "Epoch 19/75\n",
      "3063/3063 [==============================] - 28s 9ms/step - loss: 38.3085 - journey_loss: 34.6497 - t_kl_divergence: 4.6907 - c_divergence: 11.3324 - val_journey_loss: 0.8463 - val_context_loss: 0.4589\n",
      "Current KL Weight is 0.3\n",
      "Epoch 20/75\n",
      "3063/3063 [==============================] - 26s 9ms/step - loss: 38.8867 - journey_loss: 34.7066 - t_kl_divergence: 3.8681 - c_divergence: 8.5435 - val_journey_loss: 0.8207 - val_context_loss: 0.4614\n",
      "Current KL Weight is 0.4\n",
      "Epoch 21/75\n",
      "3063/3063 [==============================] - 23s 7ms/step - loss: 39.0280 - journey_loss: 34.8024 - t_kl_divergence: 3.4494 - c_divergence: 5.9455 - val_journey_loss: 0.7945 - val_context_loss: 0.4658\n",
      "Current KL Weight is 0.5\n",
      "Epoch 22/75\n",
      "3063/3063 [==============================] - 23s 8ms/step - loss: 38.7987 - journey_loss: 34.8434 - t_kl_divergence: 3.0781 - c_divergence: 3.8197 - val_journey_loss: 0.8529 - val_context_loss: 0.5261\n",
      "Current KL Weight is 0.6\n",
      "Epoch 23/75\n",
      "3063/3063 [==============================] - 26s 8ms/step - loss: 38.6217 - journey_loss: 34.9449 - t_kl_divergence: 2.8191 - c_divergence: 2.3232 - val_journey_loss: 0.8911 - val_context_loss: 0.6026\n",
      "Current KL Weight is 0.70000005\n",
      "Epoch 24/75\n",
      "3063/3063 [==============================] - 26s 9ms/step - loss: 38.6013 - journey_loss: 35.0209 - t_kl_divergence: 2.6501 - c_divergence: 1.5062 - val_journey_loss: 0.8062 - val_context_loss: 0.6184\n",
      "Current KL Weight is 0.8000001\n",
      "Epoch 25/75\n",
      "3063/3063 [==============================] - 24s 8ms/step - loss: 38.7184 - journey_loss: 35.1005 - t_kl_divergence: 2.5331 - c_divergence: 1.1235 - val_journey_loss: 0.8285 - val_context_loss: 0.7087\n",
      "Current KL Weight is 0.9000001\n",
      "Epoch 26/75\n",
      "3063/3063 [==============================] - 24s 8ms/step - loss: 38.8681 - journey_loss: 35.1570 - t_kl_divergence: 2.4268 - c_divergence: 0.9435 - val_journey_loss: 0.8113 - val_context_loss: 0.6510\n",
      "Current KL Weight is 1.0\n",
      "Epoch 27/75\n",
      "3063/3063 [==============================] - 26s 8ms/step - loss: 39.0895 - journey_loss: 35.2540 - t_kl_divergence: 2.3426 - c_divergence: 0.8421 - val_journey_loss: 0.8551 - val_context_loss: 0.6053\n",
      "Current KL Weight is 1.0\n",
      "Epoch 28/75\n",
      "3063/3063 [==============================] - 24s 8ms/step - loss: 38.9498 - journey_loss: 35.2131 - t_kl_divergence: 2.3204 - c_divergence: 0.7926 - val_journey_loss: 0.8379 - val_context_loss: 0.5800\n",
      "Current KL Weight is 1.0\n",
      "Epoch 29/75\n",
      "3063/3063 [==============================] - 23s 8ms/step - loss: 38.8881 - journey_loss: 35.1972 - t_kl_divergence: 2.3247 - c_divergence: 0.7614 - val_journey_loss: 0.7913 - val_context_loss: 0.6024\n",
      "Current KL Weight is 1.0\n",
      "Epoch 30/75\n",
      "3063/3063 [==============================] - 23s 8ms/step - loss: 38.8412 - journey_loss: 35.1955 - t_kl_divergence: 2.3113 - c_divergence: 0.7423 - val_journey_loss: 0.8280 - val_context_loss: 0.5841\n",
      "Current KL Weight is 1.0\n",
      "Epoch 31/75\n",
      "3063/3063 [==============================] - 24s 8ms/step - loss: 38.7247 - journey_loss: 35.1206 - t_kl_divergence: 2.2916 - c_divergence: 0.7280 - val_journey_loss: 0.9389 - val_context_loss: 0.5441\n",
      "Current KL Weight is 1.0\n",
      "Epoch 32/75\n",
      "3063/3063 [==============================] - 24s 8ms/step - loss: 38.6938 - journey_loss: 35.1126 - t_kl_divergence: 2.2806 - c_divergence: 0.7219 - val_journey_loss: 0.8795 - val_context_loss: 0.6007\n",
      "Current KL Weight is 1.0\n",
      "Epoch 33/75\n",
      "3063/3063 [==============================] - 24s 8ms/step - loss: 38.6232 - journey_loss: 35.0729 - t_kl_divergence: 2.2604 - c_divergence: 0.7156 - val_journey_loss: 0.8238 - val_context_loss: 0.5615\n",
      "Current KL Weight is 1.0\n",
      "Epoch 34/75\n",
      "3063/3063 [==============================] - 24s 8ms/step - loss: 38.5902 - journey_loss: 35.0500 - t_kl_divergence: 2.2583 - c_divergence: 0.7101 - val_journey_loss: 0.8305 - val_context_loss: 0.5729\n",
      "Current KL Weight is 1.0\n",
      "Epoch 35/75\n",
      "3063/3063 [==============================] - 24s 8ms/step - loss: 38.5068 - journey_loss: 35.0055 - t_kl_divergence: 2.2239 - c_divergence: 0.7071 - val_journey_loss: 0.7952 - val_context_loss: 0.5417\n",
      "Current KL Weight is 1.0\n",
      "Epoch 36/75\n",
      "3063/3063 [==============================] - 25s 8ms/step - loss: 38.5022 - journey_loss: 35.0058 - t_kl_divergence: 2.2229 - c_divergence: 0.7042 - val_journey_loss: 0.8689 - val_context_loss: 0.5786\n",
      "Current KL Weight is 1.0\n",
      "Epoch 37/75\n",
      "3063/3063 [==============================] - 24s 8ms/step - loss: 38.4650 - journey_loss: 34.9798 - t_kl_divergence: 2.2129 - c_divergence: 0.7036 - val_journey_loss: 0.7946 - val_context_loss: 0.5910\n",
      "Current KL Weight is 1.0\n",
      "Epoch 38/75\n",
      "3063/3063 [==============================] - 23s 8ms/step - loss: 38.4364 - journey_loss: 34.9558 - t_kl_divergence: 2.2086 - c_divergence: 0.7035 - val_journey_loss: 0.8394 - val_context_loss: 0.5678\n",
      "Current KL Weight is 1.0\n",
      "Epoch 39/75\n",
      "3063/3063 [==============================] - 23s 7ms/step - loss: 38.4041 - journey_loss: 34.9443 - t_kl_divergence: 2.1890 - c_divergence: 0.7025 - val_journey_loss: 0.8250 - val_context_loss: 0.6233\n",
      "Current KL Weight is 1.0\n",
      "Epoch 40/75\n",
      "3063/3063 [==============================] - 23s 8ms/step - loss: 38.3714 - journey_loss: 34.9222 - t_kl_divergence: 2.1804 - c_divergence: 0.7011 - val_journey_loss: 0.8699 - val_context_loss: 0.5612\n",
      "Current KL Weight is 1.0\n",
      "Epoch 41/75\n",
      "3063/3063 [==============================] - 23s 8ms/step - loss: 38.3851 - journey_loss: 34.9351 - t_kl_divergence: 2.1796 - c_divergence: 0.7024 - val_journey_loss: 0.8539 - val_context_loss: 0.6141\n",
      "Current KL Weight is 1.0\n",
      "Epoch 42/75\n",
      "3063/3063 [==============================] - 23s 8ms/step - loss: 38.2928 - journey_loss: 34.8706 - t_kl_divergence: 2.1513 - c_divergence: 0.7037 - val_journey_loss: 0.8178 - val_context_loss: 0.5804\n",
      "Current KL Weight is 1.0\n",
      "Epoch 43/75\n",
      "3063/3063 [==============================] - 23s 7ms/step - loss: 38.3694 - journey_loss: 34.9187 - t_kl_divergence: 2.1790 - c_divergence: 0.7044 - val_journey_loss: 0.8815 - val_context_loss: 0.5566\n",
      "Current KL Weight is 1.0\n",
      "Epoch 44/75\n",
      "3063/3063 [==============================] - 23s 8ms/step - loss: 38.2730 - journey_loss: 34.8552 - t_kl_divergence: 2.1488 - c_divergence: 0.7018 - val_journey_loss: 0.8024 - val_context_loss: 0.5812\n",
      "Current KL Weight is 1.0\n",
      "Epoch 45/75\n",
      "3063/3063 [==============================] - 23s 8ms/step - loss: 38.2232 - journey_loss: 34.8317 - t_kl_divergence: 2.1236 - c_divergence: 0.7007 - val_journey_loss: 0.8007 - val_context_loss: 0.5403\n",
      "Current KL Weight is 1.0\n",
      "Epoch 46/75\n",
      "3063/3063 [==============================] - 23s 7ms/step - loss: 38.2529 - journey_loss: 34.8489 - t_kl_divergence: 2.1339 - c_divergence: 0.7030 - val_journey_loss: 0.8275 - val_context_loss: 0.5654\n",
      "Current KL Weight is 1.0\n",
      "Epoch 47/75\n",
      "3063/3063 [==============================] - 23s 8ms/step - loss: 38.2270 - journey_loss: 34.8298 - t_kl_divergence: 2.1303 - c_divergence: 0.7005 - val_journey_loss: 0.8248 - val_context_loss: 0.5449\n",
      "Current KL Weight is 1.0\n",
      "Epoch 48/75\n",
      "3063/3063 [==============================] - 23s 7ms/step - loss: 38.2089 - journey_loss: 34.8125 - t_kl_divergence: 2.1260 - c_divergence: 0.7039 - val_journey_loss: 0.8316 - val_context_loss: 0.5913\n",
      "Current KL Weight is 1.0\n",
      "Epoch 49/75\n",
      "3063/3063 [==============================] - 23s 8ms/step - loss: 38.2030 - journey_loss: 34.8146 - t_kl_divergence: 2.1174 - c_divergence: 0.7046 - val_journey_loss: 0.8477 - val_context_loss: 0.5553\n",
      "Current KL Weight is 1.0\n",
      "Epoch 50/75\n",
      "3063/3063 [==============================] - 23s 8ms/step - loss: 38.1666 - journey_loss: 34.7916 - t_kl_divergence: 2.1048 - c_divergence: 0.7040 - val_journey_loss: 0.8581 - val_context_loss: 0.5659\n",
      "Current KL Weight is 1.0\n",
      "Epoch 51/75\n",
      "3063/3063 [==============================] - 23s 8ms/step - loss: 38.1155 - journey_loss: 34.7642 - t_kl_divergence: 2.0805 - c_divergence: 0.7048 - val_journey_loss: 0.9136 - val_context_loss: 0.5753\n",
      "Current KL Weight is 1.0\n",
      "Epoch 52/75\n",
      "3063/3063 [==============================] - 23s 8ms/step - loss: 38.1341 - journey_loss: 34.7705 - t_kl_divergence: 2.0909 - c_divergence: 0.7067 - val_journey_loss: 0.8027 - val_context_loss: 0.5779\n",
      "Current KL Weight is 1.0\n",
      "Epoch 53/75\n",
      "3063/3063 [==============================] - 23s 8ms/step - loss: 38.0784 - journey_loss: 34.7373 - t_kl_divergence: 2.0714 - c_divergence: 0.7043 - val_journey_loss: 0.7926 - val_context_loss: 0.5769\n",
      "Current KL Weight is 1.0\n",
      "Epoch 54/75\n",
      "3063/3063 [==============================] - 23s 8ms/step - loss: 38.0948 - journey_loss: 34.7456 - t_kl_divergence: 2.0777 - c_divergence: 0.7064 - val_journey_loss: 0.8667 - val_context_loss: 0.5580\n",
      "Current KL Weight is 1.0\n",
      "Epoch 55/75\n",
      "3063/3063 [==============================] - 23s 8ms/step - loss: 38.0900 - journey_loss: 34.7497 - t_kl_divergence: 2.0693 - c_divergence: 0.7064 - val_journey_loss: 0.8554 - val_context_loss: 0.5389\n",
      "Current KL Weight is 1.0\n",
      "Epoch 56/75\n",
      "3063/3063 [==============================] - 23s 7ms/step - loss: 38.0348 - journey_loss: 34.7066 - t_kl_divergence: 2.0580 - c_divergence: 0.7058 - val_journey_loss: 0.8269 - val_context_loss: 0.6021\n",
      "Current KL Weight is 1.0\n",
      "Epoch 57/75\n",
      "3063/3063 [==============================] - 23s 8ms/step - loss: 38.0506 - journey_loss: 34.7177 - t_kl_divergence: 2.0613 - c_divergence: 0.7074 - val_journey_loss: 0.8288 - val_context_loss: 0.5977\n",
      "Current KL Weight is 1.0\n",
      "Epoch 58/75\n",
      "3063/3063 [==============================] - 23s 8ms/step - loss: 38.0520 - journey_loss: 34.7210 - t_kl_divergence: 2.0573 - c_divergence: 0.7098 - val_journey_loss: 0.8321 - val_context_loss: 0.5277\n",
      "Current KL Weight is 1.0\n",
      "Epoch 59/75\n",
      "3063/3063 [==============================] - 23s 8ms/step - loss: 38.0216 - journey_loss: 34.6950 - t_kl_divergence: 2.0513 - c_divergence: 0.7115 - val_journey_loss: 0.8482 - val_context_loss: 0.5939\n",
      "Current KL Weight is 1.0\n",
      "Epoch 60/75\n",
      "3063/3063 [==============================] - 23s 8ms/step - loss: 38.0219 - journey_loss: 34.6892 - t_kl_divergence: 2.0536 - c_divergence: 0.7158 - val_journey_loss: 0.8560 - val_context_loss: 0.5538\n",
      "Current KL Weight is 1.0\n",
      "Epoch 61/75\n",
      "3063/3063 [==============================] - 23s 8ms/step - loss: 37.9738 - journey_loss: 34.6651 - t_kl_divergence: 2.0312 - c_divergence: 0.7145 - val_journey_loss: 0.7735 - val_context_loss: 0.5967\n",
      "Current KL Weight is 1.0\n",
      "Epoch 62/75\n",
      "3063/3063 [==============================] - 23s 8ms/step - loss: 37.9266 - journey_loss: 34.6448 - t_kl_divergence: 2.0089 - c_divergence: 0.7102 - val_journey_loss: 0.8393 - val_context_loss: 0.5553\n",
      "Current KL Weight is 1.0\n",
      "Epoch 63/75\n",
      "3063/3063 [==============================] - 23s 8ms/step - loss: 37.9473 - journey_loss: 34.6453 - t_kl_divergence: 2.0262 - c_divergence: 0.7132 - val_journey_loss: 0.8397 - val_context_loss: 0.5617\n",
      "Current KL Weight is 1.0\n",
      "Epoch 64/75\n",
      "3063/3063 [==============================] - 23s 8ms/step - loss: 37.9582 - journey_loss: 34.6607 - t_kl_divergence: 2.0211 - c_divergence: 0.7136 - val_journey_loss: 0.8596 - val_context_loss: 0.5733\n",
      "Current KL Weight is 1.0\n",
      "Epoch 65/75\n",
      "3063/3063 [==============================] - 23s 8ms/step - loss: 37.9353 - journey_loss: 34.6463 - t_kl_divergence: 2.0124 - c_divergence: 0.7144 - val_journey_loss: 0.8830 - val_context_loss: 0.5724\n",
      "Current KL Weight is 1.0\n",
      "Epoch 66/75\n",
      "3063/3063 [==============================] - 23s 8ms/step - loss: 37.8796 - journey_loss: 34.6040 - t_kl_divergence: 1.9986 - c_divergence: 0.7154 - val_journey_loss: 0.8589 - val_context_loss: 0.5764\n",
      "Current KL Weight is 1.0\n",
      "Epoch 67/75\n",
      "3063/3063 [==============================] - 23s 8ms/step - loss: 37.9147 - journey_loss: 34.6276 - t_kl_divergence: 2.0062 - c_divergence: 0.7204 - val_journey_loss: 0.8956 - val_context_loss: 0.5470\n",
      "Current KL Weight is 1.0\n",
      "Epoch 68/75\n",
      "3063/3063 [==============================] - 23s 8ms/step - loss: 37.8761 - journey_loss: 34.6010 - t_kl_divergence: 1.9974 - c_divergence: 0.7172 - val_journey_loss: 0.8120 - val_context_loss: 0.5284\n",
      "Current KL Weight is 1.0\n",
      "Epoch 69/75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3063/3063 [==============================] - 23s 7ms/step - loss: 37.8842 - journey_loss: 34.6103 - t_kl_divergence: 1.9940 - c_divergence: 0.7195 - val_journey_loss: 0.8659 - val_context_loss: 0.5927\n",
      "Current KL Weight is 1.0\n",
      "Epoch 70/75\n",
      "3063/3063 [==============================] - 22s 7ms/step - loss: 37.8776 - journey_loss: 34.6092 - t_kl_divergence: 1.9905 - c_divergence: 0.7180 - val_journey_loss: 0.8598 - val_context_loss: 0.5688\n",
      "Current KL Weight is 1.0\n",
      "Epoch 71/75\n",
      "3063/3063 [==============================] - 23s 7ms/step - loss: 37.8786 - journey_loss: 34.5978 - t_kl_divergence: 2.0006 - c_divergence: 0.7205 - val_journey_loss: 0.8817 - val_context_loss: 0.5508\n",
      "Current KL Weight is 1.0\n",
      "Epoch 72/75\n",
      "3063/3063 [==============================] - 23s 7ms/step - loss: 37.8539 - journey_loss: 34.5879 - t_kl_divergence: 1.9862 - c_divergence: 0.7205 - val_journey_loss: 0.8103 - val_context_loss: 0.5638\n",
      "Current KL Weight is 1.0\n",
      "Epoch 73/75\n",
      "3063/3063 [==============================] - 23s 8ms/step - loss: 37.8714 - journey_loss: 34.6066 - t_kl_divergence: 1.9851 - c_divergence: 0.7210 - val_journey_loss: 0.8760 - val_context_loss: 0.5782\n",
      "Current KL Weight is 1.0\n",
      "Epoch 74/75\n",
      "3063/3063 [==============================] - 23s 8ms/step - loss: 37.8209 - journey_loss: 34.5591 - t_kl_divergence: 1.9807 - c_divergence: 0.7229 - val_journey_loss: 0.8046 - val_context_loss: 0.5490\n",
      "Current KL Weight is 1.0\n",
      "Epoch 75/75\n",
      "3063/3063 [==============================] - 24s 8ms/step - loss: 37.8362 - journey_loss: 34.5900 - t_kl_divergence: 1.9664 - c_divergence: 0.7217 - val_journey_loss: 0.8091 - val_context_loss: 0.5559\n",
      "Current KL Weight is 1.0\n"
     ]
    }
   ],
   "source": [
    "weight = K.variable(0.)\n",
    "weight._trainable = False\n",
    "#early_stopping = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=10)\n",
    "rvae = RVAE(encoder, decoder, context_decoder)\n",
    "rvae.compile(optimizer=keras.optimizers.Adam(lr=0.0001), beta=weight)\n",
    "history = rvae.fit([X_j_train, X_c_train], Y_train, validation_split=0.2, epochs=n_epochs, \n",
    "                   batch_size=32, callbacks=[AnnealingCallback(weight)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rvae' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-eb36cd5a1fa8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mactivities\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontexts\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mrvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_j_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_c_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mactivities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactivities\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"f1:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivities\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'weighted'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rvae' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "activities, contexts  = rvae.predict([X_j_test, X_c_test])\n",
    "activities = np.argmax(activities, axis=1)\n",
    "print(\"f1:\", f1_score(Y_test, activities, average='weighted'))\n",
    "print(\"accuracy:\", accuracy_score(Y_test, activities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_pos, pos_mean, pos_log_var, prior_mean_linear, prior_log_var, z_cpos, c_pos_means, c_pos_log_var = encoder([X_j_test, X_c_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = decoder.predict([prior_mean_linear, c_pos_means])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1: 0.5877686756010602\n",
      "accuracy: 0.6384978052349212\n"
     ]
    }
   ],
   "source": [
    "activities = np.argmax(predictions, axis=1)\n",
    "print(\"f1:\", f1_score(Y_test, activities, average='weighted'))\n",
    "print(\"accuracy:\", accuracy_score(Y_test, activities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 5 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 5 3 3 3 3 3 3 3 3 3 3 3 3 5 3 3 3 3 3 3 3 3 3 3 3 3 3 3 5\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 5 3 3 3 3 3 3 3 3 3 3 3 3]\n"
     ]
    }
   ],
   "source": [
    "stochastic_preds = []\n",
    "for i in range(1):\n",
    "    mu = prior_mean_linear[i].numpy()\n",
    "    mu = np.tile(mu, (100,1))\n",
    "    log_var = prior_log_var[i].numpy()\n",
    "    log_var = np.tile(log_var, (100,1))\n",
    "    mvn_mu = np.zeros(7)\n",
    "    mvn_cov = np.identity(7)\n",
    "    epsilon = np.random.multivariate_normal(mvn_mu, mvn_cov,size = 100)\n",
    "    z = np.exp(0.5 * log_var) * epsilon + mu\n",
    "    c = np.tile(c_pos_means[i].numpy(), (100,1))\n",
    "    sample = decoder.predict([z, c])\n",
    "    activities = np.argmax(sample, axis=1)\n",
    "    print(activities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "activity_decoder = {j:i for i,j in activity_encoder.items()}\n",
    "def sample_activity(probs, mode=\"max\"):\n",
    "    if mode == \"max\":\n",
    "        return np.argmax(probs)\n",
    "    elif mode ==\"multi\":\n",
    "        return np.argmax(np.random.multinomial(1, probs))\n",
    "    else:\n",
    "        return\n",
    "        \n",
    "def vrnn_generate(context, encoder, decoder, decode=\"off\"):\n",
    "    seed = [1]\n",
    "    context = context.reshape(1,context.shape[0])\n",
    "    for i in range(16):\n",
    "        seed_padded = keras.preprocessing.sequence.pad_sequences([seed], maxlen=16, padding='pre')\n",
    "        \n",
    "        z_pos, pos_mean, pos_log_var, prior_mean_linear,\\\n",
    "        prior_log_var, z_cpos, c_pos_means,c_pos_log_var = encoder([seed_padded, context])\n",
    "        \n",
    "        probs = decoder.predict([prior_mean_linear, c_pos_means])[0]\n",
    "        probs = np.asarray(probs).astype('float64')\n",
    "        probs = probs / np.sum(probs)\n",
    "        activity = sample_activity(probs, mode=\"max\")\n",
    "        seed.append(activity)\n",
    "    if decode == \"on\":\n",
    "        seed = [activity_decoder[s] for s in seed]\n",
    "    return seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Start',\n",
       " 'All other home activities',\n",
       " 'Routine Shopping',\n",
       " 'All other home activities',\n",
       " 'Routine Shopping',\n",
       " 'All other home activities',\n",
       " 'End',\n",
       " 'End',\n",
       " 'End',\n",
       " 'End',\n",
       " 'End',\n",
       " 'End',\n",
       " 'End',\n",
       " 'End',\n",
       " 'End',\n",
       " 'End',\n",
       " 'End']"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vrnn_generate(X_c_test[0], encoder, decoder, decode=\"on\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 3, 5, 3, 5, 3], dtype=int32)"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_j_test[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "       1.], dtype=float32)"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_c_test[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research env",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
