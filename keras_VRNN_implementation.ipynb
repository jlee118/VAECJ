{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-c3eb9a6ead37>:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  journeys_data['Activity Label'] = journeys_data['Activity'].apply(lambda x: activity_encoder[x])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "data = pd.read_csv('data/chicago.csv')\n",
    "\n",
    "# Contextual Activity\n",
    "context_data = data[['Case ID', '(case) customer:age', '(case) customer:currently_student', '(case) customer:household_income',\n",
    "                    '(case) customer:employment_status', '(case) customer:disabled']]\n",
    "\n",
    "# Journey Data\n",
    "all_activities = pd.unique(data['Activity'])\n",
    "activity_encoder = dict(zip(all_activities,range(3,len(all_activities) + 3)))\n",
    "activity_encoder['Start'] = 1\n",
    "activity_encoder['End'] = 2\n",
    "journeys_data = data[['Case ID','Activity']]\n",
    "journeys_data['Activity Label'] = journeys_data['Activity'].apply(lambda x: activity_encoder[x])\n",
    "journeys_data = journeys_data.groupby(['Case ID'])['Activity Label'].apply(list)\n",
    "journeys_data = journeys_data.reset_index(name=\"Activity\")\n",
    "journeys_data['Activity'] = journeys_data['Activity'].apply(lambda x: [1] + x + [2])\n",
    "journey_vecs = keras.preprocessing.sequence.pad_sequences(journeys_data['Activity'], padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = data[['(case) time:DATE_day_of_week_0_is_monday', '(case) customer:employed',\n",
    "               '(case) customer:currently_student', '(case) customer:valid_license']]\n",
    "context = pd.get_dummies(context, columns=['(case) time:DATE_day_of_week_0_is_monday', '(case) customer:employed',\n",
    "                                          '(case) customer:currently_student','(case) customer:valid_license'])\n",
    "context = pd.concat([data['Case ID'], context], axis=1)\n",
    "context.drop_duplicates(subset='Case ID', inplace=True)\n",
    "context.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "id_train, id_test = train_test_split(journeys_data['Case ID'], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Many to one + context\n",
    "def mto_lstm_prep(journey):\n",
    "    inp = [journey[:i] for i in range(1,len(journey))]\n",
    "    out = journey[1:]\n",
    "    return (inp,out)\n",
    "\n",
    "def make_data(id_indexes, journey_df, context_df):\n",
    "    X_j = []\n",
    "    Y = []\n",
    "    X_c = []\n",
    "\n",
    "    selected = journey_df.iloc[id_indexes]\n",
    "\n",
    "    for index, row in selected.iterrows():\n",
    "        inp, out = mto_lstm_prep(row['Activity'])\n",
    "        rep = len(inp)\n",
    "        c = context_df.iloc[index].drop(labels=['index','Case ID']).to_numpy()\n",
    "        c = np.tile(c, (rep, 1))\n",
    "        X_j.extend(inp)\n",
    "        Y.extend(out)\n",
    "        X_c.extend(c)\n",
    "    X_j = keras.preprocessing.sequence.pad_sequences(X_j, padding='pre')\n",
    "    X_c = np.asarray(X_c).astype(\"float32\")\n",
    "    Y = np.asarray(Y).astype(\"float32\")\n",
    "    return (X_j, X_c, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_j_train, X_c_train, Y_train = make_data(id_train.index, journeys_data, context)\n",
    "X_j_test, X_c_test, Y_test = make_data(id_test.index, journeys_data, context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VRNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "# Implementing Variational RNN's and variations by subclassing Keras RNN-type Cells\n",
    "\n",
    "class VRNNCell(tf.keras.layers.GRUCell):\n",
    "    def __init__(self, units, **kwargs):\n",
    "        super(VRNNCell, self).__init__(units, **kwargs)\n",
    "    \n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Taking most of the standard weight initiaalizations from the base GRU class\n",
    "        super().build((input_shape[0], input_shape[1] + self.units))\n",
    "        \n",
    "        self.input_kernel = self.add_weight(shape=(input_shape[-1], input_shape[-1]), initializer='uniform')\n",
    "        \n",
    "        self.state_kernel = self.add_weight(shape=(self.units, self.units), initializer='uniform')\n",
    "        \n",
    "        self.encoder_mu_kernel = self.add_weight(shape=(input_shape[-1] + self.units, self.units), initializer='uniform')\n",
    "        \n",
    "        self.encoder_logvar_kernel = self.add_weight(shape=(input_shape[-1] + self.units, self.units), initializer='uniform')\n",
    "        \n",
    "        self.prior_mu_kernel = self.add_weight(shape=(self.units, self.units), initializer='uniform')\n",
    "        \n",
    "        self.prior_logvar_kernel = self.add_weight(shape=(self.units, self.units), initializer='uniform')  \n",
    "\n",
    "\n",
    "    def sample(self, mu, log_var):\n",
    "        # Sample from unit Normal\n",
    "        epsilon = tf.random.normal([1, self.units])\n",
    "        half_constant = tf.convert_to_tensor(np.full((1, self.units), 0.5).astype('float32'))\n",
    "        # All element-wise computations\n",
    "        z = tf.math.multiply(half_constant, tf.math.exp(log_var)) + mu\n",
    "        return z\n",
    "    \n",
    "    def call(self, inputs, states, training=False):\n",
    "        # Some formulations:\n",
    "        # Generation:\n",
    "        # z_t ~ N(mu_(0, t), sigma_(0,t)), w here [mu_(0,t), sigma(0,t)] = phi_prior(h_(t-1))\n",
    "        # Update: \n",
    "        # h_t = f_theta(h_(t-1), z_t, x_t) *recurrence equation\n",
    "        # Inference:\n",
    "        # z_t ~ N(mu_z, sigma_z), where [mu_z, sigma_z] = phi_post(x_t, h_(t-1))\n",
    "        #\n",
    "        # Let the base RNN cell handle the rest and add loss\n",
    "        \n",
    "        if training:\n",
    "            x_t = tf.matmul(inputs, self.input_kernel)\n",
    "            h_prev = tf.matmul(states[0], self.state_kernel)\n",
    "\n",
    "            p_mu = tf.matmul(h_prev, self.prior_mu_kernel)\n",
    "            p_logvar = tf.matmul(h_prev, self.prior_logvar_kernel)\n",
    "            \n",
    "            input_state_concat = tf.concat([x_t, h_prev], axis=1)\n",
    "            \n",
    "            q_mu = tf.matmul(input_state_concat, self.encoder_mu_kernel)\n",
    "            q_logvar = tf.matmul(input_state_concat, self.encoder_logvar_kernel)\n",
    "            z_t = self.sample(q_mu, q_logvar)\n",
    "            \n",
    "            inp = tf.concat([x_t, z_t], axis=1)\n",
    "            _, h_next = super().call(inp, h_prev)\n",
    "            \n",
    "            output = (z_t, q_mu, p_mu, q_logvar, p_logvar)\n",
    "            # self.add_loss(self.kl_gauss(q_mu, p_mu, q_logvar, p_logvar))\n",
    "            return output, h_next\n",
    "        \n",
    "        else:\n",
    "            # Return prior and posterior parameters\n",
    "            x_t = inputs\n",
    "            h_prev = states[0]\n",
    "\n",
    "            p_mu = tf.matmul(h_prev, self.prior_mu_kernel)\n",
    "            p_logvar = tf.matmul(h_prev, self.prior_logvar_kernel)\n",
    "            z_t = self.sample(p_mu, p_logvar)\n",
    "            \n",
    "            input_state_concat = tf.concat([x_t, h_prev], axis=1)\n",
    "            \n",
    "            q_mu = tf.matmul(input_state_concat, self.encoder_mu_kernel)\n",
    "            q_logvar = tf.matmul(input_state_concat, self.encoder_logvar_kernel)\n",
    "            \n",
    "            \n",
    "            i = tf.concat([x_t, z_t], axis=1)\n",
    "            _, h_next = super().call(i, h_prev)\n",
    "            \n",
    "            output = (z_t, q_mu, p_mu, q_logvar, p_logvar)\n",
    "            \n",
    "            return z_t, h_next\n",
    "    \n",
    "   \n",
    "    def get_config(self):\n",
    "        return {\"units\":self.units}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kl_gauss(posterior_means, prior_means, posterior_log_var, prior_log_var):   \n",
    "    kl = prior_log_var - posterior_log_var + (tf.exp(posterior_log_var) + \n",
    "                                       tf.square(posterior_means - prior_means)) / tf.exp(prior_log_var) - 1\n",
    "    kl = 0.5 * tf.reduce_sum(kl)\n",
    "    return kl\n",
    "\n",
    "class VRNNGRU(tf.keras.Model):\n",
    "    def __init__(self, vrnn, **kwargs):\n",
    "        super(VRNNGRU, self).__init__(**kwargs)\n",
    "        self.vrnn = vrnn\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
    "            name=\"reconstruction_loss\"\n",
    "        )\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "        \n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "        ]\n",
    "\n",
    "    def train_step(self, data):\n",
    "        if isinstance(data, tuple):\n",
    "            input_data = data[0]\n",
    "            output_data = data[1]\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            outputs = self.vrnn(input_data, training=True)\n",
    "            preds = tf.slice(outputs[0], \n",
    "            print(preds)\n",
    "            q_mu = tf.squeeze(tf.squeeze(outputs[1]))\n",
    "            p_mu = tf.squeeze(tf.squeeze(outputs[2]))\n",
    "            q_log_var = tf.squeeze(tf.squeeze(outputs[3]))\n",
    "            p_log_var = tf.squeeze(tf.squeeze(outputs[4]))\n",
    "            \n",
    "            kl_loss = tf.reduce_mean(kl_gauss(q_mu, p_mu, q_log_var, p_log_var))\n",
    "            reconstruction_loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(output_data, preds))\n",
    "            total_loss = reconstruction_loss + kl_loss \n",
    "            \n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)       \n",
    "        return {\n",
    "            'total_loss': self.total_loss_tracker.result(),\n",
    "            'loss': self.reconstruction_loss_tracker.result(),\n",
    "            'kl': self.kl_loss_tracker.result()\n",
    "        }\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        outputs = self.vrnn(inputs, training)\n",
    "        return outputs\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "batch_size = 64\n",
    "timesteps = 20\n",
    "\n",
    "cell = VRNNCell(3)\n",
    "vrnn = keras.layers.RNN(cell, return_sequences=True)\n",
    "\n",
    "X = np.random.random((batch_size * 1, timesteps, 32))\n",
    "Y = np.random.random((batch_size * 1, 3))\n",
    "\n",
    "rvae = VRNNGRU(vrnn)\n",
    "rvae.compile(optimizer=keras.optimizers.Adam(lr=0.001))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "Tensor(\"rnn_23/transpose_1:0\", shape=(1, 20, 3), dtype=float32)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    c:\\users\\jchle\\work\\thesis\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:855 train_function  *\n        return step_function(self, iterator)\n    c:\\users\\jchle\\work\\thesis\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:845 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    c:\\users\\jchle\\work\\thesis\\venv\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1285 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    c:\\users\\jchle\\work\\thesis\\venv\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2833 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    c:\\users\\jchle\\work\\thesis\\venv\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3608 _call_for_each_replica\n        return fn(*args, **kwargs)\n    c:\\users\\jchle\\work\\thesis\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:838 run_step  **\n        outputs = model.train_step(data)\n    <ipython-input-88-e61cf0c866a9>:40 train_step\n        reconstruction_loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(output_data, preds))\n    c:\\users\\jchle\\work\\thesis\\venv\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    c:\\users\\jchle\\work\\thesis\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:1643 categorical_crossentropy\n        return backend.categorical_crossentropy(\n    c:\\users\\jchle\\work\\thesis\\venv\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    c:\\users\\jchle\\work\\thesis\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py:4862 categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n    c:\\users\\jchle\\work\\thesis\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py:1161 assert_is_compatible_with\n        raise ValueError(\"Shapes %s and %s are incompatible\" % (self, other))\n\n    ValueError: Shapes (1, 3) and (1, 20, 3) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-90-b306dee91507>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0minput_1_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimesteps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtarget_1_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mrvae\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_1_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_1_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\jchle\\work\\thesis\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1181\u001b[0m                 _r=1):\n\u001b[0;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1183\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1184\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jchle\\work\\thesis\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jchle\\work\\thesis\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    931\u001b[0m       \u001b[1;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 933\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    934\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m       \u001b[1;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jchle\\work\\thesis\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    761\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    762\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m--> 763\u001b[1;33m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m    764\u001b[0m             *args, **kwds))\n\u001b[0;32m    765\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jchle\\work\\thesis\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3048\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3049\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3050\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3051\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3052\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jchle\\work\\thesis\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3442\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3443\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3444\u001b[1;33m           \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3445\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3446\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jchle\\work\\thesis\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3277\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3278\u001b[0m     graph_function = ConcreteFunction(\n\u001b[1;32m-> 3279\u001b[1;33m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[0;32m   3280\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3281\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jchle\\work\\thesis\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    997\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    998\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 999\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1000\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1001\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jchle\\work\\thesis\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    670\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    671\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 672\u001b[1;33m           \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    673\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    674\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jchle\\work\\thesis\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    984\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    985\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 986\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    987\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    988\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    c:\\users\\jchle\\work\\thesis\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:855 train_function  *\n        return step_function(self, iterator)\n    c:\\users\\jchle\\work\\thesis\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:845 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    c:\\users\\jchle\\work\\thesis\\venv\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1285 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    c:\\users\\jchle\\work\\thesis\\venv\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2833 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    c:\\users\\jchle\\work\\thesis\\venv\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3608 _call_for_each_replica\n        return fn(*args, **kwargs)\n    c:\\users\\jchle\\work\\thesis\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:838 run_step  **\n        outputs = model.train_step(data)\n    <ipython-input-88-e61cf0c866a9>:40 train_step\n        reconstruction_loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(output_data, preds))\n    c:\\users\\jchle\\work\\thesis\\venv\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    c:\\users\\jchle\\work\\thesis\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:1643 categorical_crossentropy\n        return backend.categorical_crossentropy(\n    c:\\users\\jchle\\work\\thesis\\venv\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    c:\\users\\jchle\\work\\thesis\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py:4862 categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n    c:\\users\\jchle\\work\\thesis\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py:1161 assert_is_compatible_with\n        raise ValueError(\"Shapes %s and %s are incompatible\" % (self, other))\n\n    ValueError: Shapes (1, 3) and (1, 20, 3) are incompatible\n"
     ]
    }
   ],
   "source": [
    "input_1_data = np.random.random((batch_size * 1, timesteps, 32))\n",
    "target_1_data = np.random.random((batch_size * 1, 3))\n",
    "rvae.fit(input_1_data, target_1_data, batch_size=1, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell = VRNNCell(3)\n",
    "vrnn = keras.layers.RNN(cell)\n",
    "\n",
    "input_1 = keras.Input((None, 32))\n",
    "output = vrnn(input_1, training=True)\n",
    "model = keras.models.Model(input_1, output)\n",
    "model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 2s 17ms/step - loss: 2.3022 - rnn_1_loss: 1.1103 - rnn_1_1_loss: 0.3017 - rnn_1_2_loss: 0.3071 - rnn_1_3_loss: 0.2825 - rnn_1_4_loss: 0.3006 - rnn_1_accuracy: 0.2969 - rnn_1_1_accuracy: 0.2969 - rnn_1_2_accuracy: 0.2969 - rnn_1_3_accuracy: 0.3125 - rnn_1_4_accuracy: 0.2969\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x28123e202e0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X,Y )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(64, 3), dtype=float32, numpy=\n",
       " array([[0.50068074, 0.5292831 , 0.49616778],\n",
       "        [0.46271214, 0.5261049 , 0.5048643 ],\n",
       "        [0.48982954, 0.5320121 , 0.50850064],\n",
       "        [0.452219  , 0.518947  , 0.507816  ],\n",
       "        [0.5122242 , 0.52833474, 0.5048509 ],\n",
       "        [0.4915202 , 0.5279296 , 0.51092076],\n",
       "        [0.5003726 , 0.5333755 , 0.5105326 ],\n",
       "        [0.48690113, 0.5302101 , 0.5068163 ],\n",
       "        [0.4777823 , 0.52243525, 0.50713694],\n",
       "        [0.47992167, 0.5169551 , 0.51436675],\n",
       "        [0.5010537 , 0.5340675 , 0.510652  ],\n",
       "        [0.4922114 , 0.5282726 , 0.49006072],\n",
       "        [0.48289537, 0.52634203, 0.5137888 ],\n",
       "        [0.48125413, 0.52143514, 0.5062611 ],\n",
       "        [0.4625477 , 0.5223661 , 0.5075189 ],\n",
       "        [0.48342434, 0.5331997 , 0.50072455],\n",
       "        [0.4521863 , 0.5157041 , 0.5132326 ],\n",
       "        [0.4834373 , 0.53055817, 0.50949186],\n",
       "        [0.48872975, 0.52493936, 0.5047332 ],\n",
       "        [0.4389698 , 0.50863194, 0.5096451 ],\n",
       "        [0.48403248, 0.5371503 , 0.4846415 ],\n",
       "        [0.47041968, 0.5259546 , 0.4962358 ],\n",
       "        [0.48446596, 0.5307677 , 0.5068287 ],\n",
       "        [0.4522073 , 0.5232105 , 0.50249326],\n",
       "        [0.49990302, 0.51590824, 0.5116967 ],\n",
       "        [0.47959822, 0.5256521 , 0.5156382 ],\n",
       "        [0.46344241, 0.5262401 , 0.50081795],\n",
       "        [0.4792387 , 0.52910614, 0.49988902],\n",
       "        [0.49942002, 0.53033406, 0.50740534],\n",
       "        [0.49901015, 0.5339385 , 0.51046777],\n",
       "        [0.4587601 , 0.5182995 , 0.513511  ],\n",
       "        [0.48429623, 0.5314698 , 0.5042857 ],\n",
       "        [0.47746775, 0.52841043, 0.5055213 ],\n",
       "        [0.46182466, 0.52293515, 0.5007224 ],\n",
       "        [0.48938528, 0.52084136, 0.51956   ],\n",
       "        [0.48139963, 0.52471966, 0.5138265 ],\n",
       "        [0.50012887, 0.5388305 , 0.4931094 ],\n",
       "        [0.44419578, 0.5174309 , 0.5052795 ],\n",
       "        [0.48524147, 0.5219412 , 0.5099448 ],\n",
       "        [0.5017277 , 0.5319271 , 0.50387067],\n",
       "        [0.4887922 , 0.5231036 , 0.50969934],\n",
       "        [0.47071782, 0.52574724, 0.5111517 ],\n",
       "        [0.51639783, 0.54313904, 0.49032387],\n",
       "        [0.48311472, 0.5260421 , 0.5107088 ],\n",
       "        [0.52693284, 0.5519484 , 0.48923093],\n",
       "        [0.48429406, 0.53229624, 0.50552225],\n",
       "        [0.485034  , 0.52332336, 0.5104436 ],\n",
       "        [0.48258865, 0.51431656, 0.50804806],\n",
       "        [0.47981414, 0.5322759 , 0.5011277 ],\n",
       "        [0.49151236, 0.5367358 , 0.4986723 ],\n",
       "        [0.47356474, 0.51906437, 0.5070009 ],\n",
       "        [0.4634499 , 0.52652335, 0.50238603],\n",
       "        [0.48953527, 0.52632964, 0.5081434 ],\n",
       "        [0.4761136 , 0.53253525, 0.50031054],\n",
       "        [0.4860345 , 0.53052735, 0.50773114],\n",
       "        [0.48883265, 0.52248096, 0.5072733 ],\n",
       "        [0.4921254 , 0.5312676 , 0.50644743],\n",
       "        [0.46050748, 0.5250146 , 0.49896502],\n",
       "        [0.49910343, 0.5339483 , 0.5048492 ],\n",
       "        [0.4791172 , 0.53351706, 0.49279994],\n",
       "        [0.48310643, 0.52468693, 0.49947715],\n",
       "        [0.47147647, 0.51711655, 0.51629126],\n",
       "        [0.48489216, 0.52947766, 0.50705874],\n",
       "        [0.4818839 , 0.5248216 , 0.5113405 ]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(64, 3), dtype=float32, numpy=\n",
       " array([[ 2.01003812e-03,  1.02603715e-02,  6.52549416e-03],\n",
       "        [-2.29519233e-02,  1.34751284e-02,  6.07946049e-03],\n",
       "        [-3.87957110e-03,  1.00518148e-02,  1.81523599e-02],\n",
       "        [-3.02512478e-02,  1.22191263e-02,  4.21239249e-03],\n",
       "        [ 1.05663706e-02,  6.05049822e-03,  1.79635119e-02],\n",
       "        [-2.76227901e-03,  7.90564902e-03,  1.96762867e-02],\n",
       "        [ 3.50671378e-03,  8.27991869e-03,  2.31163930e-02],\n",
       "        [-6.13743346e-03,  1.03487661e-02,  1.50828222e-02],\n",
       "        [-1.27649857e-02,  9.27893352e-03,  1.06243081e-02],\n",
       "        [-1.09572830e-02,  5.48821734e-03,  1.68435536e-02],\n",
       "        [ 4.02083760e-03,  8.36063456e-03,  2.36309748e-02],\n",
       "        [-4.36194008e-03,  1.27391322e-02, -2.20378395e-03],\n",
       "        [-8.39557126e-03,  8.15204903e-03,  2.02317107e-02],\n",
       "        [-1.05726682e-02,  8.58734269e-03,  1.01252412e-02],\n",
       "        [-2.30441745e-02,  1.16834352e-02,  7.52338348e-03],\n",
       "        [-8.89617298e-03,  1.32924831e-02,  8.88223201e-03],\n",
       "        [-2.99514066e-02,  9.92678944e-03,  8.78997799e-03],\n",
       "        [-8.18514079e-03,  1.04100192e-02,  1.72690954e-02],\n",
       "        [-5.45441173e-03,  8.83989036e-03,  1.14307702e-02],\n",
       "        [-3.97729352e-02,  1.06394440e-02, -7.60888215e-04],\n",
       "        [-9.83440224e-03,  1.81898400e-02, -6.67597307e-03],\n",
       "        [-1.85978245e-02,  1.41464965e-02, -1.38815399e-03],\n",
       "        [-7.74259400e-03,  1.09255640e-02,  1.47455977e-02],\n",
       "        [-3.05056199e-02,  1.48272933e-02,  9.27748115e-05],\n",
       "        [ 2.17428780e-03,  2.48724432e-03,  1.81528926e-02],\n",
       "        [-1.04832863e-02,  8.04602448e-03,  2.12098043e-02],\n",
       "        [-2.28487644e-02,  1.43324835e-02,  1.99207431e-03],\n",
       "        [-1.20690009e-02,  1.28628109e-02,  5.61600272e-03],\n",
       "        [ 2.35778559e-03,  8.19329359e-03,  1.85386650e-02],\n",
       "        [ 2.62029935e-03,  8.69832933e-03,  2.29406934e-02],\n",
       "        [-2.52869669e-02,  9.61426552e-03,  1.15579255e-02],\n",
       "        [-8.06500576e-03,  1.17684929e-02,  1.22532928e-02],\n",
       "        [-1.27498740e-02,  1.16267921e-02,  1.09543800e-02],\n",
       "        [-2.41706036e-02,  1.35546587e-02,  3.30523995e-04],\n",
       "        [-3.79804196e-03,  3.98033811e-03,  2.58866474e-02],\n",
       "        [-9.50687751e-03,  7.86943454e-03,  1.93630885e-02],\n",
       "        [ 1.94938586e-03,  1.41153000e-02,  6.46183360e-03],\n",
       "        [-3.60599160e-02,  1.36409346e-02, -9.19252692e-04],\n",
       "        [-7.48107815e-03,  7.24233268e-03,  1.51237147e-02],\n",
       "        [ 3.65726394e-03,  9.14553553e-03,  1.58500224e-02],\n",
       "        [-5.03548421e-03,  7.08916271e-03,  1.60742197e-02],\n",
       "        [-1.69286672e-02,  1.05823325e-02,  1.44637842e-02],\n",
       "        [ 1.28505034e-02,  1.34716006e-02,  8.52823909e-03],\n",
       "        [-8.57354328e-03,  8.73360038e-03,  1.69040617e-02],\n",
       "        [ 2.03386862e-02,  1.47934221e-02,  1.25788348e-02],\n",
       "        [-7.89008755e-03,  1.17463628e-02,  1.38543118e-02],\n",
       "        [-7.48129096e-03,  7.60562671e-03,  1.60959251e-02],\n",
       "        [-9.96057689e-03,  5.65484772e-03,  9.78257321e-03],\n",
       "        [-1.13520408e-02,  1.34980809e-02,  8.17685947e-03],\n",
       "        [-3.42281349e-03,  1.35681648e-02,  9.73637030e-03],\n",
       "        [-1.58501938e-02,  8.91734101e-03,  8.31239112e-03],\n",
       "        [-2.26699375e-02,  1.40604163e-02,  3.76282330e-03],\n",
       "        [-4.48053423e-03,  8.36367346e-03,  1.57231409e-02],\n",
       "        [-1.39159951e-02,  1.43811516e-02,  6.56720111e-03],\n",
       "        [-6.61017746e-03,  1.03807459e-02,  1.59709565e-02],\n",
       "        [-5.29129384e-03,  7.44401012e-03,  1.32854367e-02],\n",
       "        [-2.58583319e-03,  9.91301890e-03,  1.62260048e-02],\n",
       "        [-2.51019336e-02,  1.48498416e-02, -1.09308469e-03],\n",
       "        [ 2.12186039e-03,  9.99394991e-03,  1.70059279e-02],\n",
       "        [-1.25710331e-02,  1.59416664e-02, -3.88143817e-04],\n",
       "        [-9.78740770e-03,  1.08995689e-02,  4.48801927e-03],\n",
       "        [-1.64670218e-02,  6.48831995e-03,  1.70185342e-02],\n",
       "        [-7.51544069e-03,  1.03887888e-02,  1.46338930e-02],\n",
       "        [-9.42068268e-03,  8.39818828e-03,  1.68671608e-02]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(64, 3), dtype=float32, numpy=\n",
       " array([[-2.66214809e-03,  3.73397022e-02, -2.09329557e-02],\n",
       "        [-2.90909186e-02,  2.49458756e-02, -2.43328349e-03],\n",
       "        [-1.26615837e-02,  4.29834463e-02, -1.94922742e-02],\n",
       "        [-3.56889069e-02,  1.33659653e-02,  7.18136737e-03],\n",
       "        [ 3.31018562e-03,  4.36037406e-02, -2.65752003e-02],\n",
       "        [-1.15009174e-02,  3.92667167e-02, -1.76662449e-02],\n",
       "        [-6.28794823e-03,  4.89722304e-02, -2.54896618e-02],\n",
       "        [-1.40206721e-02,  3.89539748e-02, -1.66712217e-02],\n",
       "        [-1.90864392e-02,  2.59723589e-02, -6.99919695e-03],\n",
       "        [-1.84105504e-02,  2.26746257e-02, -4.96594422e-03],\n",
       "        [-5.95195452e-03,  5.01357280e-02, -2.63007656e-02],\n",
       "        [-6.87693525e-03,  3.05942502e-02, -1.55919222e-02],\n",
       "        [-1.75715741e-02,  3.57338302e-02, -1.29694911e-02],\n",
       "        [-1.64814834e-02,  2.53709592e-02, -7.75830494e-03],\n",
       "        [-2.92396396e-02,  2.11402532e-02, -8.95003723e-06],\n",
       "        [-1.54781053e-02,  3.90423387e-02, -1.64499022e-02],\n",
       "        [-3.63784023e-02,  1.14883156e-02,  8.84610228e-03],\n",
       "        [-1.68971010e-02,  3.95056419e-02, -1.56766567e-02],\n",
       "        [-1.16998525e-02,  3.16914059e-02, -1.34857092e-02],\n",
       "        [-4.34447303e-02, -4.02306020e-03,  2.05984674e-02],\n",
       "        [-1.23420898e-02,  3.72196212e-02, -1.75176542e-02],\n",
       "        [-2.22098399e-02,  2.33416501e-02, -4.76343045e-03],\n",
       "        [-1.57056134e-02,  3.89169566e-02, -1.59604754e-02],\n",
       "        [-3.51859778e-02,  1.66274346e-02,  4.78948094e-03],\n",
       "        [-4.55290219e-03,  2.64881067e-02, -1.29964817e-02],\n",
       "        [-2.00363677e-02,  3.46063226e-02, -1.12057636e-02],\n",
       "        [-2.78005768e-02,  2.35361308e-02, -2.35093711e-03],\n",
       "        [-1.75375212e-02,  3.19701880e-02, -1.15200747e-02],\n",
       "        [-5.89289051e-03,  4.33290713e-02, -2.25182530e-02],\n",
       "        [-7.24648032e-03,  4.92475145e-02, -2.52622664e-02],\n",
       "        [-3.24259400e-02,  1.72213521e-02,  3.89851234e-03],\n",
       "        [-1.53954038e-02,  3.86461020e-02, -1.60635877e-02],\n",
       "        [-1.97586324e-02,  3.30162086e-02, -1.09256972e-02],\n",
       "        [-2.84092650e-02,  1.85872857e-02,  7.83492171e-04],\n",
       "        [-1.37271732e-02,  3.31659764e-02, -1.27341095e-02],\n",
       "        [-1.83544401e-02,  3.31450738e-02, -1.11349802e-02],\n",
       "        [-3.64761637e-03,  4.82475273e-02, -2.70678923e-02],\n",
       "        [-4.02894616e-02,  7.55134318e-03,  1.23213017e-02],\n",
       "        [-1.46618923e-02,  2.89739612e-02, -1.04117962e-02],\n",
       "        [-3.86661477e-03,  4.45555113e-02, -2.42503677e-02],\n",
       "        [-1.24214543e-02,  3.15266848e-02, -1.28317131e-02],\n",
       "        [-2.50173956e-02,  2.98789255e-02, -6.64633093e-03],\n",
       "        [ 7.06958119e-03,  5.76412715e-02, -3.70880552e-02],\n",
       "        [-1.67632215e-02,  3.40312347e-02, -1.24679236e-02],\n",
       "        [ 1.31020024e-02,  7.16785863e-02, -4.78212237e-02],\n",
       "        [-1.57551914e-02,  4.02775817e-02, -1.68045275e-02],\n",
       "        [-1.50826527e-02,  3.09514981e-02, -1.13689862e-02],\n",
       "        [-1.50136650e-02,  1.71750579e-02, -3.47501785e-03],\n",
       "        [-1.78255942e-02,  3.68675776e-02, -1.41985351e-02],\n",
       "        [-1.01812873e-02,  4.52938229e-02, -2.23765969e-02],\n",
       "        [-2.13974230e-02,  2.00909115e-02, -2.62639718e-03],\n",
       "        [-2.81529650e-02,  2.46203355e-02, -2.75738258e-03],\n",
       "        [-1.20405760e-02,  3.53014879e-02, -1.52755398e-02],\n",
       "        [-2.01423950e-02,  3.56645323e-02, -1.25922458e-02],\n",
       "        [-1.48198484e-02,  3.95026803e-02, -1.66169014e-02],\n",
       "        [-1.18217412e-02,  2.96305269e-02, -1.20971827e-02],\n",
       "        [-1.06338644e-02,  4.18222286e-02, -1.97509136e-02],\n",
       "        [-2.92034894e-02,  2.01256629e-02,  1.16238327e-04],\n",
       "        [-6.05518743e-03,  4.67964150e-02, -2.46139634e-02],\n",
       "        [-1.67631935e-02,  3.45470496e-02, -1.37174930e-02],\n",
       "        [-1.43142864e-02,  2.72014569e-02, -1.00722779e-02],\n",
       "        [-2.44084746e-02,  2.10336838e-02, -1.45558780e-03],\n",
       "        [-1.53012881e-02,  3.74669880e-02, -1.52661605e-02],\n",
       "        [-1.75438058e-02,  3.23188044e-02, -1.11149661e-02]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(64, 3), dtype=float32, numpy=\n",
       " array([[-0.00435387, -0.00406926, -0.05079177],\n",
       "        [ 0.0629066 , -0.01498814, -0.04425139],\n",
       "        [ 0.05138261,  0.00213172, -0.03821855],\n",
       "        [ 0.01217088, -0.03136417, -0.07488918],\n",
       "        [ 0.09558116, -0.04303933,  0.05837893],\n",
       "        [ 0.02713056,  0.02019892, -0.09690099],\n",
       "        [ 0.05827838,  0.00665426, -0.08613864],\n",
       "        [-0.034412  , -0.01211249,  0.01659087],\n",
       "        [ 0.11493024, -0.07972495, -0.03182365],\n",
       "        [ 0.03558363, -0.01083358, -0.070959  ],\n",
       "        [ 0.08154113, -0.01265271, -0.08496474],\n",
       "        [ 0.09475563, -0.03213484, -0.03257439],\n",
       "        [ 0.02471847,  0.07251203, -0.00166523],\n",
       "        [ 0.07197532, -0.05736476, -0.04405521],\n",
       "        [ 0.07338738, -0.09064119,  0.00326789],\n",
       "        [ 0.01909059,  0.0173874 , -0.09933923],\n",
       "        [ 0.06784867,  0.06973235, -0.02734259],\n",
       "        [ 0.08853319, -0.04511751, -0.01482618],\n",
       "        [ 0.07031998,  0.00265966,  0.04397013],\n",
       "        [ 0.0358291 ,  0.01132875,  0.00876491],\n",
       "        [-0.03644088,  0.05518112, -0.02393807],\n",
       "        [-0.05813145,  0.01190357, -0.04897174],\n",
       "        [ 0.01881396, -0.06380961, -0.01609408],\n",
       "        [ 0.09052256, -0.05844952, -0.06065798],\n",
       "        [ 0.00720529,  0.06789644,  0.00798115],\n",
       "        [ 0.02915368, -0.044849  , -0.11905704],\n",
       "        [ 0.19448222, -0.06118973,  0.1123317 ],\n",
       "        [ 0.01985887, -0.07855871, -0.1545585 ],\n",
       "        [-0.00262184, -0.00133632, -0.0113956 ],\n",
       "        [ 0.13875481,  0.04836408, -0.00233831],\n",
       "        [ 0.043945  , -0.13641597, -0.01247715],\n",
       "        [ 0.02147761,  0.05550544,  0.01234445],\n",
       "        [-0.03445981, -0.01042093, -0.1096671 ],\n",
       "        [-0.00366474, -0.0006325 , -0.09901079],\n",
       "        [-0.05706142, -0.02963165, -0.02247099],\n",
       "        [-0.02421614,  0.01984637,  0.00581697],\n",
       "        [ 0.0012571 , -0.04383341, -0.06542121],\n",
       "        [ 0.00809996, -0.04681901, -0.07024267],\n",
       "        [-0.02228981, -0.06161187, -0.01628001],\n",
       "        [ 0.098585  , -0.02339844, -0.04593539],\n",
       "        [ 0.04995637,  0.03632265,  0.01734729],\n",
       "        [ 0.03661278, -0.05928752, -0.12242375],\n",
       "        [ 0.0189248 ,  0.00483427, -0.11663345],\n",
       "        [ 0.12284707,  0.03224508,  0.03180337],\n",
       "        [ 0.03211666,  0.03714372, -0.0501363 ],\n",
       "        [ 0.00379282, -0.0088232 , -0.08591505],\n",
       "        [ 0.06250641, -0.12073467, -0.00534375],\n",
       "        [ 0.04498364,  0.02564741, -0.00377185],\n",
       "        [ 0.00807572,  0.05897977, -0.01433126],\n",
       "        [-0.03398338,  0.03078824, -0.1018798 ],\n",
       "        [-0.01442171,  0.00720415,  0.02122231],\n",
       "        [ 0.11928524, -0.03407007,  0.0028516 ],\n",
       "        [ 0.04809836,  0.08824472, -0.06940524],\n",
       "        [ 0.04321546,  0.08658307, -0.01801936],\n",
       "        [ 0.05777562, -0.00760934,  0.00858787],\n",
       "        [ 0.0488912 ,  0.00569551, -0.01082717],\n",
       "        [ 0.05050689,  0.02308626, -0.03480484],\n",
       "        [ 0.12157799, -0.00087173,  0.09856554],\n",
       "        [ 0.05333248, -0.06813249, -0.00025846],\n",
       "        [ 0.07878985, -0.0351261 , -0.07178228],\n",
       "        [ 0.10474473, -0.05934533, -0.02196461],\n",
       "        [ 0.06701074, -0.05269607, -0.05707477],\n",
       "        [ 0.0365941 , -0.0729441 , -0.07229627],\n",
       "        [-0.0137367 , -0.01030388, -0.05094315]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(64, 3), dtype=float32, numpy=\n",
       " array([[ 0.09285749, -0.15594983,  0.13056952],\n",
       "        [ 0.12706597, -0.05762368,  0.12551264],\n",
       "        [ 0.12392244, -0.05183249,  0.12573658],\n",
       "        [ 0.10914405, -0.04111751,  0.03361824],\n",
       "        [ 0.04766984, -0.07725238,  0.0458251 ],\n",
       "        [ 0.12561083, -0.0635899 ,  0.05915535],\n",
       "        [ 0.07933   , -0.04418165,  0.02388049],\n",
       "        [ 0.17486712, -0.00179333,  0.0839645 ],\n",
       "        [ 0.08806027, -0.00741993, -0.02366194],\n",
       "        [ 0.07215906, -0.04292241,  0.09885556],\n",
       "        [ 0.09322774, -0.01463347,  0.06341485],\n",
       "        [ 0.07943603, -0.10663904,  0.07927359],\n",
       "        [ 0.15292628, -0.02186932,  0.02305211],\n",
       "        [ 0.08549341, -0.08485243,  0.08512018],\n",
       "        [-0.02515638, -0.01130839,  0.06824916],\n",
       "        [ 0.04487463, -0.04027156,  0.10819436],\n",
       "        [ 0.03139507, -0.04808047,  0.03747036],\n",
       "        [ 0.02685869, -0.06698287,  0.11792711],\n",
       "        [ 0.11859153,  0.02751406,  0.0656984 ],\n",
       "        [ 0.06658605, -0.02008514,  0.01272504],\n",
       "        [ 0.13365605,  0.01376959,  0.1228507 ],\n",
       "        [ 0.1878992 ,  0.01503132,  0.19200152],\n",
       "        [ 0.19065723, -0.04315174,  0.09259804],\n",
       "        [ 0.05177544, -0.15686841,  0.09919644],\n",
       "        [ 0.12265556, -0.05121917,  0.12022694],\n",
       "        [ 0.09880634, -0.01931793,  0.06679746],\n",
       "        [-0.00433356, -0.0243747 ,  0.04486573],\n",
       "        [ 0.1028142 , -0.12028848,  0.09977222],\n",
       "        [ 0.07416517, -0.0739288 ,  0.18392657],\n",
       "        [ 0.14745793, -0.07101724,  0.02329339],\n",
       "        [ 0.162907  , -0.03681801,  0.04235865],\n",
       "        [ 0.12070983,  0.0427678 ,  0.10239142],\n",
       "        [ 0.14308393, -0.04654006,  0.11279523],\n",
       "        [ 0.07046095,  0.02067579,  0.11438845],\n",
       "        [ 0.12993142, -0.06729025,  0.11613707],\n",
       "        [ 0.07642907, -0.05069545,  0.1406758 ],\n",
       "        [ 0.10746667, -0.03215716,  0.08329026],\n",
       "        [ 0.09717014, -0.07922675,  0.03552464],\n",
       "        [ 0.0868049 , -0.08025273,  0.03142839],\n",
       "        [ 0.11225511, -0.08276148,  0.06733628],\n",
       "        [ 0.03539545,  0.04202876,  0.05826152],\n",
       "        [ 0.1048682 ,  0.01359447,  0.05702194],\n",
       "        [ 0.18418834, -0.01980161,  0.10539124],\n",
       "        [ 0.09064158,  0.02963959,  0.03372698],\n",
       "        [ 0.07380491, -0.02704553,  0.10330532],\n",
       "        [ 0.10785117,  0.01913708,  0.07118747],\n",
       "        [ 0.13086839,  0.015825  ,  0.06500164],\n",
       "        [ 0.13195755, -0.01895302,  0.02568048],\n",
       "        [ 0.00403554, -0.06112656,  0.06482337],\n",
       "        [ 0.07960219, -0.05900789,  0.10131373],\n",
       "        [ 0.12423871,  0.10593281,  0.05984756],\n",
       "        [ 0.04636246, -0.12964979,  0.06636644],\n",
       "        [ 0.08281081, -0.07230981,  0.03538712],\n",
       "        [ 0.06392004,  0.00070251,  0.08493145],\n",
       "        [ 0.10104486, -0.05597394,  0.03934921],\n",
       "        [ 0.11185873, -0.0005745 ,  0.07129472],\n",
       "        [ 0.06645673, -0.05578865,  0.16445167],\n",
       "        [ 0.09906194, -0.09323706,  0.08546341],\n",
       "        [ 0.08484972, -0.01937683,  0.04545744],\n",
       "        [ 0.05779924, -0.08688461,  0.11409994],\n",
       "        [ 0.1548339 ,  0.01435515, -0.04795856],\n",
       "        [ 0.16194993, -0.06398287,  0.01970929],\n",
       "        [ 0.08386334, -0.12409576,  0.04005809],\n",
       "        [ 0.0942091 , -0.08962366,  0.08471119]], dtype=float32)>)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vrnn(input_1_data, training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(64, 3), dtype=float32, numpy=\n",
       " array([[0.48544663, 0.50757957, 0.4699906 ],\n",
       "        [0.50136703, 0.50307465, 0.49709392],\n",
       "        [0.48719135, 0.50693065, 0.4732785 ],\n",
       "        [0.4811251 , 0.5139315 , 0.45654422],\n",
       "        [0.48267457, 0.5189062 , 0.45178062],\n",
       "        [0.4924169 , 0.5194061 , 0.46450275],\n",
       "        [0.4944159 , 0.5097243 , 0.47875574],\n",
       "        [0.4922774 , 0.5230228 , 0.4596571 ],\n",
       "        [0.4844971 , 0.51291144, 0.46177593],\n",
       "        [0.4838476 , 0.52520555, 0.44552037],\n",
       "        [0.4860503 , 0.50793403, 0.46988666],\n",
       "        [0.48626116, 0.51788074, 0.45810208],\n",
       "        [0.5016757 , 0.51223445, 0.48537055],\n",
       "        [0.4957752 , 0.527188  , 0.4598345 ],\n",
       "        [0.48279372, 0.5172111 , 0.45413494],\n",
       "        [0.4909631 , 0.5158375 , 0.46712944],\n",
       "        [0.5005782 , 0.5119957 , 0.48472178],\n",
       "        [0.48909238, 0.52358216, 0.45513284],\n",
       "        [0.4848975 , 0.51882964, 0.4550278 ],\n",
       "        [0.49085367, 0.5058539 , 0.47870076],\n",
       "        [0.48968858, 0.500719  , 0.48392573],\n",
       "        [0.48220634, 0.52151525, 0.44827813],\n",
       "        [0.50214934, 0.50887823, 0.49030712],\n",
       "        [0.49110422, 0.52027756, 0.46181992],\n",
       "        [0.4910052 , 0.5141872 , 0.46935102],\n",
       "        [0.49573812, 0.5144662 , 0.4749335 ],\n",
       "        [0.4897557 , 0.515544  , 0.46554178],\n",
       "        [0.4811044 , 0.5078615 , 0.4639244 ],\n",
       "        [0.49810505, 0.5125083 , 0.48043925],\n",
       "        [0.5018445 , 0.5115461 , 0.4871413 ],\n",
       "        [0.49293795, 0.51794314, 0.46721858],\n",
       "        [0.49928582, 0.51820284, 0.4751948 ],\n",
       "        [0.48699376, 0.5292063 , 0.44521275],\n",
       "        [0.48685315, 0.51722944, 0.45957544],\n",
       "        [0.48288122, 0.5127763 , 0.45963046],\n",
       "        [0.4779434 , 0.5149917 , 0.4503004 ],\n",
       "        [0.47842288, 0.53472793, 0.4270864 ],\n",
       "        [0.49073738, 0.5158829 , 0.46691024],\n",
       "        [0.4999955 , 0.5147633 , 0.48023114],\n",
       "        [0.49122304, 0.5219794 , 0.45985395],\n",
       "        [0.47215056, 0.514618  , 0.44323483],\n",
       "        [0.50565016, 0.51992196, 0.48159844],\n",
       "        [0.4970245 , 0.52425355, 0.46474275],\n",
       "        [0.47845614, 0.52512497, 0.43887913],\n",
       "        [0.49114767, 0.5138401 , 0.46959803],\n",
       "        [0.48666108, 0.5176062 , 0.4588708 ],\n",
       "        [0.48584253, 0.5141461 , 0.46232548],\n",
       "        [0.4811483 , 0.5156627 , 0.4542483 ],\n",
       "        [0.5019029 , 0.5176028 , 0.47930518],\n",
       "        [0.4889059 , 0.5189236 , 0.46035454],\n",
       "        [0.4984252 , 0.5086813 , 0.4860875 ],\n",
       "        [0.48840693, 0.52868783, 0.4482932 ],\n",
       "        [0.4889908 , 0.5137526 , 0.46669844],\n",
       "        [0.48537025, 0.50143653, 0.47692412],\n",
       "        [0.49800885, 0.5105915 , 0.4832106 ],\n",
       "        [0.4981675 , 0.52438414, 0.46645555],\n",
       "        [0.4877563 , 0.5158936 , 0.46286288],\n",
       "        [0.49651042, 0.5274013 , 0.4602181 ],\n",
       "        [0.4794548 , 0.51789427, 0.4493153 ],\n",
       "        [0.48620635, 0.5236175 , 0.4509845 ],\n",
       "        [0.49375808, 0.5174384 , 0.4684443 ],\n",
       "        [0.48006257, 0.52043355, 0.44633853],\n",
       "        [0.49455112, 0.51054347, 0.4782748 ],\n",
       "        [0.48778445, 0.5265655 , 0.4498246 ]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(64, 3), dtype=float32, numpy=\n",
       " array([[-1.36286672e-02,  1.98506401e-03, -1.74816847e-02],\n",
       "        [ 3.62488063e-04, -2.47280975e-03, -1.01287046e-03],\n",
       "        [-1.21677248e-02,  2.25273543e-03, -1.56697147e-02],\n",
       "        [-2.03399267e-02,  1.02529824e-02, -2.70659477e-02],\n",
       "        [-2.10063681e-02,  1.09216608e-02, -2.98962444e-02],\n",
       "        [-1.45432539e-02,  1.40076103e-02, -2.33015828e-02],\n",
       "        [-7.40663148e-03, -7.42033662e-05, -1.19434614e-02],\n",
       "        [-1.63794961e-02,  1.69374645e-02, -2.67221797e-02],\n",
       "        [-1.66984554e-02,  5.36643015e-03, -2.29207948e-02],\n",
       "        [-2.34621391e-02,  1.78511497e-02, -3.50428335e-02],\n",
       "        [-1.28029352e-02, -1.01295812e-03, -1.68282352e-02],\n",
       "        [-1.81649029e-02,  1.17701916e-02, -2.64706593e-02],\n",
       "        [-3.36854137e-03,  2.56479927e-03, -8.75699986e-03],\n",
       "        [-1.68563463e-02,  2.64781285e-02, -2.88160387e-02],\n",
       "        [-2.01489720e-02,  9.76912491e-03, -2.82928776e-02],\n",
       "        [-1.38786957e-02,  1.09661901e-02, -2.11275425e-02],\n",
       "        [-4.68507502e-03,  6.06956892e-03, -9.96502768e-03],\n",
       "        [-1.95012409e-02,  2.04862263e-02, -3.01499777e-02],\n",
       "        [-1.95708964e-02,  1.22508444e-02, -2.83389892e-02],\n",
       "        [-7.91943073e-03, -4.84148692e-03, -1.09003456e-02],\n",
       "        [-6.65035471e-03, -7.24651199e-03, -7.41433026e-03],\n",
       "        [-2.31596157e-02,  1.63981114e-02, -3.31636183e-02],\n",
       "        [-1.39232760e-03, -3.24840192e-04, -5.30331582e-03],\n",
       "        [-1.61487032e-02,  1.60583705e-02, -2.53125466e-02],\n",
       "        [-1.31091857e-02,  9.92384646e-03, -1.96315907e-02],\n",
       "        [-9.29816533e-03,  7.35386508e-03, -1.58233810e-02],\n",
       "        [-1.42118931e-02,  8.25955532e-03, -2.14025639e-02],\n",
       "        [-1.70908067e-02,  2.99504353e-03, -2.11989079e-02],\n",
       "        [-6.39479421e-03,  4.39870544e-03, -1.20033259e-02],\n",
       "        [-3.69312521e-03,  6.61643315e-03, -8.72359611e-03],\n",
       "        [-1.36160012e-02,  1.37520786e-02, -2.17056032e-02],\n",
       "        [-8.86697974e-03,  1.26613807e-02, -1.68804619e-02],\n",
       "        [-2.38857083e-02,  2.58899033e-02, -3.70496027e-02],\n",
       "        [-1.72358472e-02,  1.01490319e-02, -2.52509899e-02],\n",
       "        [-1.76264364e-02,  4.08414844e-03, -2.38551702e-02],\n",
       "        [-2.24089194e-02,  6.45996770e-03, -2.97595188e-02],\n",
       "        [-3.32041271e-02,  3.26558873e-02, -4.90272492e-02],\n",
       "        [-1.42268650e-02,  1.19679365e-02, -2.14895401e-02],\n",
       "        [-6.27544615e-03,  7.36074429e-03, -1.27939964e-02],\n",
       "        [-1.69571750e-02,  1.79125927e-02, -2.68542953e-02],\n",
       "        [-2.67093051e-02,  7.41890445e-03, -3.40728834e-02],\n",
       "        [-5.14022540e-03,  1.47046428e-02, -1.36890942e-02],\n",
       "        [-1.38978763e-02,  2.03348901e-02, -2.45919619e-02],\n",
       "        [-2.78824512e-02,  2.07834207e-02, -3.95662300e-02],\n",
       "        [-1.23859812e-02,  6.93146186e-03, -1.87868681e-02],\n",
       "        [-1.75986812e-02,  1.07046776e-02, -2.57816222e-02],\n",
       "        [-1.66898351e-02,  8.72420520e-03, -2.33787131e-02],\n",
       "        [-2.10164078e-02,  1.08734844e-02, -2.85089854e-02],\n",
       "        [-6.45379722e-03,  1.09480200e-02, -1.41350143e-02],\n",
       "        [-1.67942122e-02,  1.30525744e-02, -2.54635625e-02],\n",
       "        [-4.67504282e-03,  3.31849465e-03, -8.57875030e-03],\n",
       "        [-2.31977496e-02,  2.90613733e-02, -3.60298678e-02],\n",
       "        [-1.37788858e-02,  5.96348615e-03, -2.02221870e-02],\n",
       "        [-9.84353479e-03, -8.64276662e-03, -1.10815540e-02],\n",
       "        [-6.05439954e-03,  5.84402075e-03, -1.07930899e-02],\n",
       "        [-1.35218408e-02,  2.28218567e-02, -2.41995081e-02],\n",
       "        [-1.63693465e-02,  1.16625717e-02, -2.37385202e-02],\n",
       "        [-1.60675291e-02,  2.45253108e-02, -2.81308927e-02],\n",
       "        [-2.35284306e-02,  1.39143029e-02, -3.20341736e-02],\n",
       "        [-2.13305801e-02,  1.86981037e-02, -3.21146026e-02],\n",
       "        [-1.21544702e-02,  9.66200326e-03, -2.00426485e-02],\n",
       "        [-2.36308165e-02,  1.20267104e-02, -3.32737602e-02],\n",
       "        [-8.17133207e-03,  3.40481801e-03, -1.30320610e-02],\n",
       "        [-2.22107656e-02,  2.48071384e-02, -3.41774411e-02]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(64, 3), dtype=float32, numpy=\n",
       " array([[-0.0018511 ,  0.01112687, -0.02537465],\n",
       "        [ 0.00200702,  0.01103388, -0.00379362],\n",
       "        [-0.00128268,  0.00931226, -0.02235153],\n",
       "        [ 0.00292578,  0.00733007, -0.03332894],\n",
       "        [ 0.0073349 ,  0.0158429 , -0.03733466],\n",
       "        [ 0.01382432,  0.01073901, -0.02469375],\n",
       "        [ 0.00363846,  0.01940751, -0.01877679],\n",
       "        [ 0.01716562,  0.01209708, -0.02761932],\n",
       "        [ 0.0023883 ,  0.01497722, -0.03108474],\n",
       "        [ 0.01451365,  0.0146016 , -0.03964937],\n",
       "        [-0.00229616,  0.01773586, -0.02692955],\n",
       "        [ 0.00881314,  0.01214697, -0.03134053],\n",
       "        [ 0.010038  ,  0.01915471, -0.01181442],\n",
       "        [ 0.02494924,  0.00141878, -0.0229605 ],\n",
       "        [ 0.00586812,  0.01477418, -0.03577682],\n",
       "        [ 0.00963701,  0.00969552, -0.02376619],\n",
       "        [ 0.01047162,  0.01178252, -0.01068325],\n",
       "        [ 0.01704125,  0.00617275, -0.02987628],\n",
       "        [ 0.00889703,  0.01307175, -0.03383235],\n",
       "        [-0.00245684,  0.02116525, -0.02101709],\n",
       "        [-0.0073491 ,  0.01580541, -0.01747159],\n",
       "        [ 0.01067473,  0.0101822 , -0.03782289],\n",
       "        [ 0.00705833,  0.0182388 , -0.00881787],\n",
       "        [ 0.01440165,  0.00840298, -0.02607201],\n",
       "        [ 0.00819511,  0.00849059, -0.02228115],\n",
       "        [ 0.01002215,  0.01412449, -0.01865919],\n",
       "        [ 0.0079038 ,  0.01446382, -0.02645827],\n",
       "        [-0.00361611,  0.00968594, -0.03020501],\n",
       "        [ 0.00895942,  0.01608896, -0.01523027],\n",
       "        [ 0.01101437,  0.0098111 , -0.00830457],\n",
       "        [ 0.01302276,  0.00834719, -0.02240065],\n",
       "        [ 0.01617402,  0.01102191, -0.01597644],\n",
       "        [ 0.02152551,  0.00661077, -0.03611987],\n",
       "        [ 0.00814477,  0.01406156, -0.03081713],\n",
       "        [ 0.00101482,  0.01723489, -0.03358651],\n",
       "        [ 0.00070435,  0.01691953, -0.04069715],\n",
       "        [ 0.02298784,  0.00413551, -0.0489515 ],\n",
       "        [ 0.00987949,  0.00779945, -0.02347382],\n",
       "        [ 0.01246385,  0.01469655, -0.01404798],\n",
       "        [ 0.01622807,  0.00810071, -0.02694322],\n",
       "        [-0.00228284,  0.01429545, -0.04644673],\n",
       "        [ 0.02135123,  0.0103806 , -0.00946965],\n",
       "        [ 0.02160958,  0.0078068 , -0.02156139],\n",
       "        [ 0.01259751,  0.0086456 , -0.04406613],\n",
       "        [ 0.00704249,  0.01372265, -0.02350427],\n",
       "        [ 0.00848339,  0.01370857, -0.03117609],\n",
       "        [ 0.00505193,  0.01078534, -0.02900835],\n",
       "        [ 0.00432016,  0.0095329 , -0.03509405],\n",
       "        [ 0.0165753 ,  0.01322179, -0.01320646],\n",
       "        [ 0.01133568,  0.0116736 , -0.02877385],\n",
       "        [ 0.00618127,  0.01066853, -0.01072482],\n",
       "        [ 0.02294404, -0.00074735, -0.03185588],\n",
       "        [ 0.00552412,  0.01545806, -0.026507  ],\n",
       "        [-0.00961858,  0.01995821, -0.02428105],\n",
       "        [ 0.00809363,  0.00945022, -0.01206511],\n",
       "        [ 0.02310967,  0.00311974, -0.01886674],\n",
       "        [ 0.00821747,  0.00842652, -0.02716274],\n",
       "        [ 0.02484471,  0.00573563, -0.02357781],\n",
       "        [ 0.00594872,  0.00792846, -0.0380145 ],\n",
       "        [ 0.01496139,  0.00979072, -0.03438626],\n",
       "        [ 0.01175571,  0.01543305, -0.02329537],\n",
       "        [ 0.00735962,  0.01667381, -0.04163007],\n",
       "        [ 0.00543012,  0.01417638, -0.01753921],\n",
       "        [ 0.0197933 ,  0.00351055, -0.03251893]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(64, 3), dtype=float32, numpy=\n",
       " array([[-5.81451915e-02, -2.94608604e-02, -5.35388291e-03],\n",
       "        [-8.56350362e-03,  2.80150585e-02,  9.37383622e-02],\n",
       "        [-4.27900180e-02, -3.20777036e-02,  3.27765122e-02],\n",
       "        [-1.80990789e-02, -7.63657540e-02, -4.70922887e-03],\n",
       "        [ 5.14225475e-02, -4.44664992e-02, -8.75355750e-02],\n",
       "        [-1.33910820e-01,  1.53320683e-02,  5.14462478e-02],\n",
       "        [ 1.08024016e-01, -9.87941399e-02, -4.10647206e-02],\n",
       "        [ 6.52646422e-02, -7.86576718e-02,  3.17011327e-02],\n",
       "        [-5.80820106e-02,  7.03476137e-03, -7.68832490e-03],\n",
       "        [-3.23491134e-02, -1.19377844e-01,  1.46450149e-02],\n",
       "        [-1.16915435e-01, -4.41053845e-02,  2.49288622e-02],\n",
       "        [ 4.56514396e-02, -7.76954144e-02,  1.98114030e-02],\n",
       "        [ 5.89995235e-02, -4.10132855e-02, -8.10175296e-03],\n",
       "        [-2.78167911e-02, -4.57513407e-02, -5.57698160e-02],\n",
       "        [ 7.24666640e-02, -1.16000280e-01, -9.14428732e-04],\n",
       "        [ 4.04297411e-02, -6.86835423e-02,  3.33170518e-02],\n",
       "        [-1.17012078e-03, -4.61337566e-02, -3.84317786e-02],\n",
       "        [ 1.52126886e-02, -9.32353437e-02, -4.63942774e-02],\n",
       "        [ 5.51607013e-02, -1.09295540e-01,  2.83765551e-02],\n",
       "        [-1.10150598e-01, -4.97578718e-02, -6.21714331e-02],\n",
       "        [ 1.34273078e-02, -5.30201383e-02,  4.38745655e-02],\n",
       "        [-1.98146701e-02, -4.88546044e-02,  8.53231549e-03],\n",
       "        [-6.48874650e-03, -6.80772364e-02,  4.74453118e-05],\n",
       "        [ 5.99216670e-02,  5.48243662e-03,  1.59923378e-02],\n",
       "        [ 1.83745497e-03, -2.19249185e-02, -2.40930207e-02],\n",
       "        [-3.96530069e-02, -5.85212894e-02,  2.88865082e-02],\n",
       "        [-1.65476445e-02, -7.67587349e-02, -1.34286717e-01],\n",
       "        [-6.79228455e-02, -1.82000566e-02, -2.98439320e-02],\n",
       "        [ 4.14006859e-02, -4.43750136e-02,  1.84223875e-02],\n",
       "        [ 1.51848393e-02, -2.01296341e-02,  3.73104028e-02],\n",
       "        [ 3.67877930e-02, -6.47341311e-02, -4.04120944e-02],\n",
       "        [-1.54306442e-02, -4.97970767e-02,  9.77988448e-03],\n",
       "        [-1.01733664e-02, -1.57848019e-02,  8.23177025e-02],\n",
       "        [ 4.41416539e-02, -3.81340273e-02,  7.78668211e-04],\n",
       "        [-2.00701617e-02, -9.49634761e-02, -9.35695507e-03],\n",
       "        [ 7.99739733e-03, -1.18306115e-01,  3.20823491e-02],\n",
       "        [-1.39607638e-02, -6.20380305e-02,  1.62990484e-02],\n",
       "        [-4.16310355e-02, -9.02161896e-02, -5.16390130e-02],\n",
       "        [ 6.86714426e-03, -7.49209747e-02,  4.30922955e-03],\n",
       "        [ 5.36571629e-02, -1.20644689e-01, -1.23950187e-02],\n",
       "        [-1.00898348e-01, -6.76694140e-02, -2.05802638e-02],\n",
       "        [ 1.50194382e-02,  1.90063193e-02,  5.10070994e-02],\n",
       "        [-1.60200708e-02, -8.49195421e-02,  6.42176112e-03],\n",
       "        [-2.01308001e-02, -5.09048440e-02,  2.49930024e-02],\n",
       "        [-5.40420189e-02, -1.70103693e-03,  5.77662401e-02],\n",
       "        [-6.87945560e-02, -3.65693346e-02,  3.19474824e-02],\n",
       "        [-7.93199986e-02, -1.30042518e-02,  3.39968577e-02],\n",
       "        [-5.30001372e-02, -2.29107365e-02, -8.34647417e-02],\n",
       "        [ 3.30602787e-02, -5.23412302e-02, -5.12744859e-02],\n",
       "        [-5.04454738e-03, -5.20187151e-03,  2.06614845e-02],\n",
       "        [ 8.32916647e-02, -2.12150794e-02,  1.84293874e-02],\n",
       "        [ 8.62023458e-02, -2.19980329e-02, -5.08527309e-02],\n",
       "        [ 4.37917188e-02, -3.09896329e-03,  4.35555726e-02],\n",
       "        [-3.97984311e-02, -8.77466202e-02,  6.38705194e-02],\n",
       "        [ 2.35338490e-02,  2.24117679e-03, -2.98943780e-02],\n",
       "        [ 9.51822177e-02, -1.04835518e-01,  2.01642103e-02],\n",
       "        [-3.42722572e-02, -4.22625430e-02, -3.26323994e-02],\n",
       "        [-4.51235138e-02, -7.99260139e-02, -4.66024876e-02],\n",
       "        [-7.43243545e-02,  9.00556799e-03, -3.57693732e-02],\n",
       "        [-5.57721630e-02, -3.22919637e-02,  4.93211634e-02],\n",
       "        [-2.99943821e-03, -6.03490695e-02, -3.13983373e-02],\n",
       "        [-3.38920653e-02, -1.31321233e-02,  2.75362264e-02],\n",
       "        [-1.00444525e-01,  3.85990292e-02, -6.66645020e-02],\n",
       "        [-1.81224756e-02, -8.22052062e-02, -2.44160630e-02]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(64, 3), dtype=float32, numpy=\n",
       " array([[-0.02309517, -0.01951064, -0.03575448],\n",
       "        [ 0.06900033,  0.14541711, -0.0296631 ],\n",
       "        [ 0.01827559,  0.12694359,  0.03130323],\n",
       "        [ 0.0076467 ,  0.11359628, -0.02518263],\n",
       "        [-0.09653318,  0.05879879, -0.06156722],\n",
       "        [ 0.0018962 ,  0.10095777, -0.01914315],\n",
       "        [-0.03051189,  0.10574261,  0.00513282],\n",
       "        [ 0.06551404, -0.02152822, -0.05775876],\n",
       "        [ 0.07494659,  0.11461212, -0.14329576],\n",
       "        [-0.00477549,  0.09352645, -0.00231798],\n",
       "        [ 0.02563855,  0.08976363,  0.00350787],\n",
       "        [-0.04085108,  0.08133865, -0.00055993],\n",
       "        [ 0.00311645,  0.04274461, -0.02755087],\n",
       "        [ 0.06172935,  0.15240294, -0.05765316],\n",
       "        [ 0.00746737,  0.02408472, -0.12257001],\n",
       "        [ 0.01953323,  0.05405311, -0.02503945],\n",
       "        [-0.00205157,  0.06664132, -0.1003636 ],\n",
       "        [ 0.03299918,  0.10907219, -0.00064373],\n",
       "        [-0.02404642,  0.06403057, -0.07777803],\n",
       "        [ 0.02540415,  0.05351209, -0.06698103],\n",
       "        [ 0.02012846,  0.09783866,  0.00385715],\n",
       "        [ 0.09158038,  0.08372216, -0.07392113],\n",
       "        [ 0.03874345,  0.11804207,  0.0036922 ],\n",
       "        [ 0.07752463,  0.06619671, -0.08193846],\n",
       "        [ 0.10846764,  0.07611447, -0.1038198 ],\n",
       "        [ 0.00871676,  0.10053881,  0.03825255],\n",
       "        [-0.000537  , -0.00611707,  0.00403487],\n",
       "        [-0.01698075,  0.08941929,  0.10399971],\n",
       "        [-0.03552585, -0.00877051,  0.02243495],\n",
       "        [ 0.0986031 ,  0.15164809, -0.03956426],\n",
       "        [ 0.02736624,  0.07515002, -0.05605753],\n",
       "        [ 0.0596728 ,  0.13333601,  0.04453712],\n",
       "        [ 0.05669619,  0.00548917,  0.01825251],\n",
       "        [-0.02517984,  0.11137383, -0.07565656],\n",
       "        [-0.01767293,  0.01024472, -0.08486571],\n",
       "        [-0.05338834,  0.03391919, -0.06552193],\n",
       "        [-0.06192818,  0.04378558,  0.02467141],\n",
       "        [-0.0758203 ,  0.01435234, -0.03487362],\n",
       "        [ 0.01761807,  0.03260539, -0.03324319],\n",
       "        [-0.12686455,  0.08596987, -0.00037726],\n",
       "        [-0.01525079,  0.07976268,  0.03867699],\n",
       "        [ 0.0886879 ,  0.12582675, -0.08092175],\n",
       "        [ 0.05268582,  0.11565398, -0.07245754],\n",
       "        [ 0.04478638,  0.04260293, -0.07894865],\n",
       "        [-0.0262071 ,  0.17286083,  0.02085668],\n",
       "        [ 0.00448259,  0.04676205, -0.01632858],\n",
       "        [ 0.02279859,  0.10819011,  0.0013388 ],\n",
       "        [ 0.02684118,  0.04125367,  0.002388  ],\n",
       "        [ 0.02505063,  0.03417218, -0.0108435 ],\n",
       "        [ 0.01062325,  0.14651814,  0.05709598],\n",
       "        [ 0.06140323,  0.02042906, -0.10673282],\n",
       "        [ 0.02075408,  0.08394181, -0.0386612 ],\n",
       "        [ 0.02637137,  0.04329728, -0.02415374],\n",
       "        [ 0.02111975,  0.13124892,  0.03879795],\n",
       "        [ 0.10151383,  0.08097006, -0.06482222],\n",
       "        [-0.00703931,  0.01964236, -0.00789726],\n",
       "        [ 0.04751512,  0.17888641, -0.09473785],\n",
       "        [ 0.10732855,  0.00934492, -0.03597455],\n",
       "        [ 0.02114088,  0.10376354, -0.0157245 ],\n",
       "        [ 0.08218475,  0.12035685,  0.00063857],\n",
       "        [ 0.09455216,  0.00820919, -0.01454678],\n",
       "        [ 0.0439204 ,  0.08256375, -0.04700107],\n",
       "        [ 0.12311266,  0.06827836, -0.03940707],\n",
       "        [-0.02847466,  0.03733611,  0.02999514]], dtype=float32)>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vrnn(input_1_data, training=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
