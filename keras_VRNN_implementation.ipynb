{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# Implementing Variational RNN's and variations by subclassing Keras RNN-type Cells\n",
    "\n",
    "class VRNNCell(tf.keras.layers.GRUCell):\n",
    "    def __init__(self, units, **kwargs):\n",
    "        super(VRNNCell, self).__init__(units, **kwargs)\n",
    "    \n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Taking most of the standard weights from the base GRU class\n",
    "        super().build((input_shape[0], input_shape[1] + self.units))\n",
    "        self.encoder_mu_kernel = self.add_weight(shape=(input_shape[-1] + self.units, self.units),\n",
    "                                                 initializer='uniform',\n",
    "                                                 name='kernel')\n",
    "        \n",
    "        self.encoder_logvar_kernel = self.add_weight(shape=(input_shape[-1] + self.units, self.units),\n",
    "                                      initializer='uniform',\n",
    "                                      name='kernel')\n",
    "        \n",
    "        self.prior_mu_kernel = self.add_weight(shape=(self.units, self.units),\n",
    "                              initializer='uniform',\n",
    "                              name='kernel')\n",
    "        \n",
    "        self.prior_logvar_kernel = self.add_weight(shape=(self.units,self.units),\n",
    "                                      initializer='uniform',\n",
    "                                      name='kernel')\n",
    "\n",
    "    def sample(self, mu, log_var):\n",
    "        # Sample from unit Normal\n",
    "        epsilon = tf.random.normal([1, self.units])\n",
    "        half_constant = tf.convert_to_tensor(np.full((1, self.units), 0.5).astype('float32'))\n",
    "        # All element-wise computations\n",
    "        z = tf.math.multiply(half_constant, tf.math.exp(log_var)) + mu\n",
    "        return z\n",
    "    \n",
    "    def call(self, inputs, states, training=False):\n",
    "        # Some formulations:\n",
    "        # Generation:\n",
    "        # z_t ~ N(mu_(0, t), sigma_(0,t)), w here [mu_(0,t), sigma(0,t)] = phi_prior(h_(t-1))\n",
    "        # Update: \n",
    "        # h_t = f_theta(h_(t-1), z_t, x_t) *recurrence equation\n",
    "        # Inference:\n",
    "        # z_t ~ N(mu_z, sigma_z), where [mu_z, sigma_z] = phi_post(x_t, h_(t-1))\n",
    "        #\n",
    "        # Let the base RNN cell handle the rest and add loss\n",
    "        \n",
    "        if training:\n",
    "            x_t = inputs\n",
    "            h_prev = states[0]\n",
    "\n",
    "            p_mu = tf.matmul(h_prev, self.prior_mu_kernel)\n",
    "            p_logvar = tf.matmul(h_prev, self.prior_logvar_kernel)\n",
    "            \n",
    "            input_state_concat = tf.concat([x_t, h_prev], axis=1)\n",
    "            \n",
    "            q_mu = tf.matmul(input_state_concat, self.encoder_mu_kernel)\n",
    "            q_logvar = tf.matmul(input_state_concat, self.encoder_logvar_kernel)\n",
    "            z_t = self.sample(q_mu, q_logvar)\n",
    "            \n",
    "            inp = tf.concat([x_t, z_t], axis=1)\n",
    "            _, h_next = super().call(inp, h_prev)\n",
    "            \n",
    "            output = z_t\n",
    "            new_state = h_next\n",
    "            \n",
    "            return output, [h_next]\n",
    "        \n",
    "        else:\n",
    "            # Return prior and posterior parameters\n",
    "            x_t = inputs\n",
    "            h_prev = states[0]\n",
    "\n",
    "            p_mu = tf.matmul(h_prev, self.prior_mu_kernel)\n",
    "            p_logvar = tf.matmul(h_prev, self.prior_logvar_kernel)\n",
    "            z_t = self.sample(p_mu, p_logvar)\n",
    "            \n",
    "            input_state_concat = tf.concat([x_t, h_prev], axis=1)\n",
    "            \n",
    "            q_mu = tf.matmul(input_state_concat, self.encoder_mu_kernel)\n",
    "            q_logvar = tf.matmul(input_state_concat, self.encoder_logvar_kernel)\n",
    "            \n",
    "            \n",
    "            i = tf.concat([x_t, z_t], axis=1)\n",
    "            _, h_next = super().call(i, h_prev)\n",
    "            \n",
    "            output = (z_t, p_mu, p_logvar, q_mu, q_logvar)\n",
    "            \n",
    "            return output, [h_next]\n",
    "\n",
    "    def get_config(self):\n",
    "        return {\"units\":self.units}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell = VRNNCell(5)\n",
    "x = tf.keras.Input((None, 32))\n",
    "layer = tf.keras.layers.RNN(cell)\n",
    "y = layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "batch_size = 64\n",
    "timesteps = 20\n",
    "\n",
    "cell = VRNNCell(3)\n",
    "vrnn = keras.layers.RNN(cell)\n",
    "input_1 = keras.Input((None, 32))\n",
    "\n",
    "outputs = vrnn(input_1, training=True)\n",
    "\n",
    "model = keras.models.Model(input_1, outputs)\n",
    "model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 1s 3ms/step - loss: 0.0808 - accuracy: 0.2536\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x17c8a6b50>"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_1_data = np.random.random((batch_size * 1, timesteps, 32))\n",
    "target_1_data = np.random.random((batch_size * 1, 3))\n",
    "model.fit(input_1_data, target_1_data, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.convert_to_tensor(np.ones([1,4]).astype('float32'))\n",
    "b = tf.convert_to_tensor(np.ones([4,3]).astype('float32'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research env",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
