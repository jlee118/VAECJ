{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "# Implementing Variational RNN's and variations by subclassing Keras RNN-type Cells\n",
    "\n",
    "class VRNNCell(tf.keras.layers.GRUCell):\n",
    "    def __init__(self, units, **kwargs):\n",
    "        super(VRNNCell, self).__init__(units, **kwargs)\n",
    "    \n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Taking most of the standard weights from the base GRU class\n",
    "        super().build((input_shape[0], input_shape[1] + self.units))\n",
    "        self.encoder_mu_kernel = self.add_weight(shape=(input_shape[-1] + self.units, self.units),\n",
    "                                                 initializer='uniform',\n",
    "                                                 name='kernel')\n",
    "        \n",
    "        self.encoder_logvar_kernel = self.add_weight(shape=(input_shape[-1] + self.units, self.units),\n",
    "                                      initializer='uniform',\n",
    "                                      name='kernel')\n",
    "        \n",
    "        self.prior_mu_kernel = self.add_weight(shape=(self.units, self.units),\n",
    "                              initializer='uniform',\n",
    "                              name='kernel')\n",
    "        \n",
    "        self.prior_logvar_kernel = self.add_weight(shape=(self.units,self.units),\n",
    "                                      initializer='uniform',\n",
    "                                      name='kernel')\n",
    "    def kl_gauss(self, posterior_means, prior_means, posterior_log_var, prior_log_var):   \n",
    "        kl = prior_log_var - posterior_log_var + (tf.exp(posterior_log_var) + \n",
    "                                           tf.square(posterior_means - prior_means)) / tf.exp(prior_log_var) - 1\n",
    "        kl = 0.5 * tf.reduce_sum(kl, axis=1)\n",
    "        return kl\n",
    "\n",
    "\n",
    "    def sample(self, mu, log_var):\n",
    "        # Sample from unit Normal\n",
    "        epsilon = tf.random.normal([1, self.units])\n",
    "        half_constant = tf.convert_to_tensor(np.full((1, self.units), 0.5).astype('float32'))\n",
    "        # All element-wise computations\n",
    "        z = tf.math.multiply(half_constant, tf.math.exp(log_var)) + mu\n",
    "        return z\n",
    "    \n",
    "    def call(self, inputs, states, training=False):\n",
    "        # Some formulations:\n",
    "        # Generation:\n",
    "        # z_t ~ N(mu_(0, t), sigma_(0,t)), w here [mu_(0,t), sigma(0,t)] = phi_prior(h_(t-1))\n",
    "        # Update: \n",
    "        # h_t = f_theta(h_(t-1), z_t, x_t) *recurrence equation\n",
    "        # Inference:\n",
    "        # z_t ~ N(mu_z, sigma_z), where [mu_z, sigma_z] = phi_post(x_t, h_(t-1))\n",
    "        #\n",
    "        # Let the base RNN cell handle the rest and add loss\n",
    "        \n",
    "        if training:\n",
    "            x_t = inputs\n",
    "            h_prev = states[0]\n",
    "\n",
    "            p_mu = tf.matmul(h_prev, self.prior_mu_kernel)\n",
    "            p_logvar = tf.matmul(h_prev, self.prior_logvar_kernel)\n",
    "            \n",
    "            input_state_concat = tf.concat([x_t, h_prev], axis=1)\n",
    "            \n",
    "            q_mu = tf.matmul(input_state_concat, self.encoder_mu_kernel)\n",
    "            q_logvar = tf.matmul(input_state_concat, self.encoder_logvar_kernel)\n",
    "            z_t = self.sample(q_mu, q_logvar)\n",
    "            \n",
    "            inp = tf.concat([x_t, z_t], axis=1)\n",
    "            _, h_next = super().call(inp, h_prev)\n",
    "            \n",
    "            output = z_t\n",
    "            new_state = (h_next, q_mu, p_mu, q_logvar, p_logvar)\n",
    "            self.add_loss(lambda: tf.reduce_sum(tf.square(inputs)))\n",
    "            return output, [h_next]\n",
    "        \n",
    "        else:\n",
    "            # Return prior and posterior parameters\n",
    "            x_t = inputs\n",
    "            h_prev = states[0]\n",
    "\n",
    "            p_mu = tf.matmul(h_prev, self.prior_mu_kernel)\n",
    "            p_logvar = tf.matmul(h_prev, self.prior_logvar_kernel)\n",
    "            z_t = self.sample(p_mu, p_logvar)\n",
    "            \n",
    "            input_state_concat = tf.concat([x_t, h_prev], axis=1)\n",
    "            \n",
    "            q_mu = tf.matmul(input_state_concat, self.encoder_mu_kernel)\n",
    "            q_logvar = tf.matmul(input_state_concat, self.encoder_logvar_kernel)\n",
    "            \n",
    "            \n",
    "            i = tf.concat([x_t, z_t], axis=1)\n",
    "            _, h_next = super().call(i, h_prev)\n",
    "            \n",
    "            output = (z_t, p_mu, p_logvar, q_mu, q_logvar)\n",
    "            \n",
    "            return output, h_next\n",
    "    \n",
    "   \n",
    "    def get_config(self):\n",
    "        return {\"units\":self.units}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell = VRNNCell(5)\n",
    "x = tf.keras.Input((None, 32))\n",
    "layer = tf.keras.layers.RNN(cell)\n",
    "y = layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "batch_size = 64\n",
    "timesteps = 20\n",
    "\n",
    "cell = VRNNCell(3)\n",
    "vrnn = keras.layers.RNN(cell)\n",
    "input_1 = keras.Input((None, 32))\n",
    "\n",
    "outputs = vrnn(input_1, training=True)\n",
    "\n",
    "model = keras.models.Model(input_1, outputs)\n",
    "model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "InaccessibleTensorError",
     "evalue": "in user code:\n\n    /Users/justinlee/Desktop/Master/Thesis/venv/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n        return step_function(self, iterator)\n    /Users/justinlee/Desktop/Master/Thesis/venv/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:795 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /Users/justinlee/Desktop/Master/Thesis/venv/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /Users/justinlee/Desktop/Master/Thesis/venv/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /Users/justinlee/Desktop/Master/Thesis/venv/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /Users/justinlee/Desktop/Master/Thesis/venv/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:788 run_step  **\n        outputs = model.train_step(data)\n    /Users/justinlee/Desktop/Master/Thesis/venv/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:756 train_step\n        y, y_pred, sample_weight, regularization_losses=self.losses)\n    /Users/justinlee/Desktop/Master/Thesis/venv/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:1477 losses\n        loss_tensor = regularizer()\n    /Users/justinlee/Desktop/Master/Thesis/venv/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:1553 _tag_callable\n        loss = loss()\n    /var/folders/q_/3vc146c52nbdzbv061fwl40w0000gn/T/tmp03szqkil.py:33 <lambda>\n        ag__.converted_call(ag__.ld(self).add_loss, (ag__.autograph_artifact((lambda : ag__.converted_call(ag__.ld(tf).reduce_sum, (ag__.converted_call(ag__.ld(tf).square, (ag__.ld(inputs),), None, fscope),), None, fscope))),), None, fscope)\n    /Users/justinlee/Desktop/Master/Thesis/venv/lib/python3.7/site-packages/tensorflow/python/ops/gen_math_ops.py:10175 square  **\n        \"Square\", x=x, name=name)\n    /Users/justinlee/Desktop/Master/Thesis/venv/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:750 _apply_op_helper\n        attrs=attr_protos, op_def=op_def)\n    /Users/justinlee/Desktop/Master/Thesis/venv/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py:588 _create_op_internal\n        inp = self.capture(inp)\n    /Users/justinlee/Desktop/Master/Thesis/venv/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py:638 capture\n        % (tensor, tensor.graph, self))\n\n    InaccessibleTensorError: The tensor 'Tensor(\"model_1/rnn_13/while/TensorArrayV2Read/TensorListGetItem:0\", shape=(1, 32), dtype=float32)' cannot be accessed here: it is defined in another function or code block. Use return values, explicit Python locals or TensorFlow collections to access it. Defined in: FuncGraph(name=model_1_rnn_13_while_body_3890, id=6236714576); accessed from: FuncGraph(name=train_function, id=6237353552).\n    \n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInaccessibleTensorError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-d9b7dd4da7ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0minput_1_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimesteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtarget_1_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_1_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_1_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/Master/Thesis/venv/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Master/Thesis/venv/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Master/Thesis/venv/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    869\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Master/Thesis/venv/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    724\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    725\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 726\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Master/Thesis/venv/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2967\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2968\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2969\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2970\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Master/Thesis/venv/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Master/Thesis/venv/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3204\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3205\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3206\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3208\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Master/Thesis/venv/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Master/Thesis/venv/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Master/Thesis/venv/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInaccessibleTensorError\u001b[0m: in user code:\n\n    /Users/justinlee/Desktop/Master/Thesis/venv/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n        return step_function(self, iterator)\n    /Users/justinlee/Desktop/Master/Thesis/venv/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:795 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /Users/justinlee/Desktop/Master/Thesis/venv/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /Users/justinlee/Desktop/Master/Thesis/venv/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /Users/justinlee/Desktop/Master/Thesis/venv/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /Users/justinlee/Desktop/Master/Thesis/venv/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:788 run_step  **\n        outputs = model.train_step(data)\n    /Users/justinlee/Desktop/Master/Thesis/venv/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:756 train_step\n        y, y_pred, sample_weight, regularization_losses=self.losses)\n    /Users/justinlee/Desktop/Master/Thesis/venv/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:1477 losses\n        loss_tensor = regularizer()\n    /Users/justinlee/Desktop/Master/Thesis/venv/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:1553 _tag_callable\n        loss = loss()\n    /var/folders/q_/3vc146c52nbdzbv061fwl40w0000gn/T/tmp03szqkil.py:33 <lambda>\n        ag__.converted_call(ag__.ld(self).add_loss, (ag__.autograph_artifact((lambda : ag__.converted_call(ag__.ld(tf).reduce_sum, (ag__.converted_call(ag__.ld(tf).square, (ag__.ld(inputs),), None, fscope),), None, fscope))),), None, fscope)\n    /Users/justinlee/Desktop/Master/Thesis/venv/lib/python3.7/site-packages/tensorflow/python/ops/gen_math_ops.py:10175 square  **\n        \"Square\", x=x, name=name)\n    /Users/justinlee/Desktop/Master/Thesis/venv/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:750 _apply_op_helper\n        attrs=attr_protos, op_def=op_def)\n    /Users/justinlee/Desktop/Master/Thesis/venv/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py:588 _create_op_internal\n        inp = self.capture(inp)\n    /Users/justinlee/Desktop/Master/Thesis/venv/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py:638 capture\n        % (tensor, tensor.graph, self))\n\n    InaccessibleTensorError: The tensor 'Tensor(\"model_1/rnn_13/while/TensorArrayV2Read/TensorListGetItem:0\", shape=(1, 32), dtype=float32)' cannot be accessed here: it is defined in another function or code block. Use return values, explicit Python locals or TensorFlow collections to access it. Defined in: FuncGraph(name=model_1_rnn_13_while_body_3890, id=6236714576); accessed from: FuncGraph(name=train_function, id=6237353552).\n    \n"
     ]
    }
   ],
   "source": [
    "input_1_data = np.random.random((batch_size * 1, timesteps, 32))\n",
    "target_1_data = np.random.random((batch_size * 1, 3))\n",
    "model.fit(input_1_data, target_1_data, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(64, 3), dtype=float32, numpy=\n",
       "array([[0.4311453 , 0.4606725 , 0.47704563],\n",
       "       [0.52808094, 0.6057584 , 0.57910377],\n",
       "       [0.46645677, 0.5354863 , 0.54857904],\n",
       "       [0.48584574, 0.48395637, 0.48264694],\n",
       "       [0.50491244, 0.48578846, 0.38260394],\n",
       "       [0.36745906, 0.5687973 , 0.54191303],\n",
       "       [0.5932691 , 0.45675448, 0.46148163],\n",
       "       [0.59921736, 0.41047204, 0.5037082 ],\n",
       "       [0.48115534, 0.56768554, 0.4255946 ],\n",
       "       [0.46520266, 0.42949104, 0.51351035],\n",
       "       [0.39687178, 0.50279284, 0.52661777],\n",
       "       [0.52611357, 0.46462557, 0.51956886],\n",
       "       [0.5612152 , 0.4806883 , 0.47820187],\n",
       "       [0.5042616 , 0.5365728 , 0.4162539 ],\n",
       "       [0.5764899 , 0.39615476, 0.44143268],\n",
       "       [0.5510044 , 0.45897853, 0.5210611 ],\n",
       "       [0.49854225, 0.48809254, 0.4138353 ],\n",
       "       [0.53186536, 0.46432456, 0.4532896 ],\n",
       "       [0.5432695 , 0.4237479 , 0.49098617],\n",
       "       [0.40357178, 0.47799325, 0.40562063],\n",
       "       [0.5237373 , 0.4983244 , 0.5457534 ],\n",
       "       [0.5278993 , 0.49468216, 0.4727844 ],\n",
       "       [0.51335835, 0.49455857, 0.5018602 ],\n",
       "       [0.6010662 , 0.5399367 , 0.47668406],\n",
       "       [0.5591872 , 0.5176001 , 0.4265686 ],\n",
       "       [0.46452355, 0.4943168 , 0.5484801 ],\n",
       "       [0.4838108 , 0.420605  , 0.3676232 ],\n",
       "       [0.42386755, 0.52856153, 0.5248556 ],\n",
       "       [0.52476674, 0.45139524, 0.52976936],\n",
       "       [0.5671918 , 0.5613703 , 0.51789814],\n",
       "       [0.55017114, 0.4738146 , 0.43222785],\n",
       "       [0.5157652 , 0.5211925 , 0.5325803 ],\n",
       "       [0.5191694 , 0.4867079 , 0.59159136],\n",
       "       [0.5319582 , 0.52057314, 0.46447504],\n",
       "       [0.470897  , 0.4099811 , 0.45002088],\n",
       "       [0.48215082, 0.3990749 , 0.5004051 ],\n",
       "       [0.4560568 , 0.45998263, 0.5287271 ],\n",
       "       [0.42217007, 0.41685188, 0.43117478],\n",
       "       [0.51597315, 0.4415655 , 0.48793843],\n",
       "       [0.49452627, 0.42395285, 0.48749736],\n",
       "       [0.39156947, 0.47401896, 0.49918553],\n",
       "       [0.5624594 , 0.58569187, 0.5123762 ],\n",
       "       [0.5111168 , 0.476126  , 0.47152272],\n",
       "       [0.5029955 , 0.470754  , 0.48689702],\n",
       "       [0.43395472, 0.59250057, 0.5682931 ],\n",
       "       [0.43345943, 0.4874427 , 0.5237815 ],\n",
       "       [0.43214822, 0.54403317, 0.5346272 ],\n",
       "       [0.46052447, 0.4977742 , 0.4177997 ],\n",
       "       [0.54651785, 0.4648377 , 0.44336528],\n",
       "       [0.5001378 , 0.57388246, 0.54997605],\n",
       "       [0.6154449 , 0.48877463, 0.46779034],\n",
       "       [0.5970959 , 0.5212313 , 0.43020296],\n",
       "       [0.5580159 , 0.51910275, 0.5316611 ],\n",
       "       [0.4711959 , 0.48229423, 0.58356994],\n",
       "       [0.5776544 , 0.5442487 , 0.43875042],\n",
       "       [0.5914817 , 0.40437537, 0.51616496],\n",
       "       [0.49016216, 0.55571085, 0.42213488],\n",
       "       [0.51143116, 0.42481387, 0.43577605],\n",
       "       [0.43679625, 0.56341356, 0.45647234],\n",
       "       [0.48727834, 0.53122324, 0.5496743 ],\n",
       "       [0.54673165, 0.44352278, 0.46149284],\n",
       "       [0.48869827, 0.5296947 , 0.5046569 ],\n",
       "       [0.46624523, 0.5737121 , 0.41411662],\n",
       "       [0.46824154, 0.4367047 , 0.4908043 ]], dtype=float32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vrnn(input_1_data, training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(64, 3), dtype=float32, numpy=\n",
       " array([[0.48544663, 0.50757957, 0.4699906 ],\n",
       "        [0.50136703, 0.50307465, 0.49709392],\n",
       "        [0.48719135, 0.50693065, 0.4732785 ],\n",
       "        [0.4811251 , 0.5139315 , 0.45654422],\n",
       "        [0.48267457, 0.5189062 , 0.45178062],\n",
       "        [0.4924169 , 0.5194061 , 0.46450275],\n",
       "        [0.4944159 , 0.5097243 , 0.47875574],\n",
       "        [0.4922774 , 0.5230228 , 0.4596571 ],\n",
       "        [0.4844971 , 0.51291144, 0.46177593],\n",
       "        [0.4838476 , 0.52520555, 0.44552037],\n",
       "        [0.4860503 , 0.50793403, 0.46988666],\n",
       "        [0.48626116, 0.51788074, 0.45810208],\n",
       "        [0.5016757 , 0.51223445, 0.48537055],\n",
       "        [0.4957752 , 0.527188  , 0.4598345 ],\n",
       "        [0.48279372, 0.5172111 , 0.45413494],\n",
       "        [0.4909631 , 0.5158375 , 0.46712944],\n",
       "        [0.5005782 , 0.5119957 , 0.48472178],\n",
       "        [0.48909238, 0.52358216, 0.45513284],\n",
       "        [0.4848975 , 0.51882964, 0.4550278 ],\n",
       "        [0.49085367, 0.5058539 , 0.47870076],\n",
       "        [0.48968858, 0.500719  , 0.48392573],\n",
       "        [0.48220634, 0.52151525, 0.44827813],\n",
       "        [0.50214934, 0.50887823, 0.49030712],\n",
       "        [0.49110422, 0.52027756, 0.46181992],\n",
       "        [0.4910052 , 0.5141872 , 0.46935102],\n",
       "        [0.49573812, 0.5144662 , 0.4749335 ],\n",
       "        [0.4897557 , 0.515544  , 0.46554178],\n",
       "        [0.4811044 , 0.5078615 , 0.4639244 ],\n",
       "        [0.49810505, 0.5125083 , 0.48043925],\n",
       "        [0.5018445 , 0.5115461 , 0.4871413 ],\n",
       "        [0.49293795, 0.51794314, 0.46721858],\n",
       "        [0.49928582, 0.51820284, 0.4751948 ],\n",
       "        [0.48699376, 0.5292063 , 0.44521275],\n",
       "        [0.48685315, 0.51722944, 0.45957544],\n",
       "        [0.48288122, 0.5127763 , 0.45963046],\n",
       "        [0.4779434 , 0.5149917 , 0.4503004 ],\n",
       "        [0.47842288, 0.53472793, 0.4270864 ],\n",
       "        [0.49073738, 0.5158829 , 0.46691024],\n",
       "        [0.4999955 , 0.5147633 , 0.48023114],\n",
       "        [0.49122304, 0.5219794 , 0.45985395],\n",
       "        [0.47215056, 0.514618  , 0.44323483],\n",
       "        [0.50565016, 0.51992196, 0.48159844],\n",
       "        [0.4970245 , 0.52425355, 0.46474275],\n",
       "        [0.47845614, 0.52512497, 0.43887913],\n",
       "        [0.49114767, 0.5138401 , 0.46959803],\n",
       "        [0.48666108, 0.5176062 , 0.4588708 ],\n",
       "        [0.48584253, 0.5141461 , 0.46232548],\n",
       "        [0.4811483 , 0.5156627 , 0.4542483 ],\n",
       "        [0.5019029 , 0.5176028 , 0.47930518],\n",
       "        [0.4889059 , 0.5189236 , 0.46035454],\n",
       "        [0.4984252 , 0.5086813 , 0.4860875 ],\n",
       "        [0.48840693, 0.52868783, 0.4482932 ],\n",
       "        [0.4889908 , 0.5137526 , 0.46669844],\n",
       "        [0.48537025, 0.50143653, 0.47692412],\n",
       "        [0.49800885, 0.5105915 , 0.4832106 ],\n",
       "        [0.4981675 , 0.52438414, 0.46645555],\n",
       "        [0.4877563 , 0.5158936 , 0.46286288],\n",
       "        [0.49651042, 0.5274013 , 0.4602181 ],\n",
       "        [0.4794548 , 0.51789427, 0.4493153 ],\n",
       "        [0.48620635, 0.5236175 , 0.4509845 ],\n",
       "        [0.49375808, 0.5174384 , 0.4684443 ],\n",
       "        [0.48006257, 0.52043355, 0.44633853],\n",
       "        [0.49455112, 0.51054347, 0.4782748 ],\n",
       "        [0.48778445, 0.5265655 , 0.4498246 ]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(64, 3), dtype=float32, numpy=\n",
       " array([[-1.36286672e-02,  1.98506401e-03, -1.74816847e-02],\n",
       "        [ 3.62488063e-04, -2.47280975e-03, -1.01287046e-03],\n",
       "        [-1.21677248e-02,  2.25273543e-03, -1.56697147e-02],\n",
       "        [-2.03399267e-02,  1.02529824e-02, -2.70659477e-02],\n",
       "        [-2.10063681e-02,  1.09216608e-02, -2.98962444e-02],\n",
       "        [-1.45432539e-02,  1.40076103e-02, -2.33015828e-02],\n",
       "        [-7.40663148e-03, -7.42033662e-05, -1.19434614e-02],\n",
       "        [-1.63794961e-02,  1.69374645e-02, -2.67221797e-02],\n",
       "        [-1.66984554e-02,  5.36643015e-03, -2.29207948e-02],\n",
       "        [-2.34621391e-02,  1.78511497e-02, -3.50428335e-02],\n",
       "        [-1.28029352e-02, -1.01295812e-03, -1.68282352e-02],\n",
       "        [-1.81649029e-02,  1.17701916e-02, -2.64706593e-02],\n",
       "        [-3.36854137e-03,  2.56479927e-03, -8.75699986e-03],\n",
       "        [-1.68563463e-02,  2.64781285e-02, -2.88160387e-02],\n",
       "        [-2.01489720e-02,  9.76912491e-03, -2.82928776e-02],\n",
       "        [-1.38786957e-02,  1.09661901e-02, -2.11275425e-02],\n",
       "        [-4.68507502e-03,  6.06956892e-03, -9.96502768e-03],\n",
       "        [-1.95012409e-02,  2.04862263e-02, -3.01499777e-02],\n",
       "        [-1.95708964e-02,  1.22508444e-02, -2.83389892e-02],\n",
       "        [-7.91943073e-03, -4.84148692e-03, -1.09003456e-02],\n",
       "        [-6.65035471e-03, -7.24651199e-03, -7.41433026e-03],\n",
       "        [-2.31596157e-02,  1.63981114e-02, -3.31636183e-02],\n",
       "        [-1.39232760e-03, -3.24840192e-04, -5.30331582e-03],\n",
       "        [-1.61487032e-02,  1.60583705e-02, -2.53125466e-02],\n",
       "        [-1.31091857e-02,  9.92384646e-03, -1.96315907e-02],\n",
       "        [-9.29816533e-03,  7.35386508e-03, -1.58233810e-02],\n",
       "        [-1.42118931e-02,  8.25955532e-03, -2.14025639e-02],\n",
       "        [-1.70908067e-02,  2.99504353e-03, -2.11989079e-02],\n",
       "        [-6.39479421e-03,  4.39870544e-03, -1.20033259e-02],\n",
       "        [-3.69312521e-03,  6.61643315e-03, -8.72359611e-03],\n",
       "        [-1.36160012e-02,  1.37520786e-02, -2.17056032e-02],\n",
       "        [-8.86697974e-03,  1.26613807e-02, -1.68804619e-02],\n",
       "        [-2.38857083e-02,  2.58899033e-02, -3.70496027e-02],\n",
       "        [-1.72358472e-02,  1.01490319e-02, -2.52509899e-02],\n",
       "        [-1.76264364e-02,  4.08414844e-03, -2.38551702e-02],\n",
       "        [-2.24089194e-02,  6.45996770e-03, -2.97595188e-02],\n",
       "        [-3.32041271e-02,  3.26558873e-02, -4.90272492e-02],\n",
       "        [-1.42268650e-02,  1.19679365e-02, -2.14895401e-02],\n",
       "        [-6.27544615e-03,  7.36074429e-03, -1.27939964e-02],\n",
       "        [-1.69571750e-02,  1.79125927e-02, -2.68542953e-02],\n",
       "        [-2.67093051e-02,  7.41890445e-03, -3.40728834e-02],\n",
       "        [-5.14022540e-03,  1.47046428e-02, -1.36890942e-02],\n",
       "        [-1.38978763e-02,  2.03348901e-02, -2.45919619e-02],\n",
       "        [-2.78824512e-02,  2.07834207e-02, -3.95662300e-02],\n",
       "        [-1.23859812e-02,  6.93146186e-03, -1.87868681e-02],\n",
       "        [-1.75986812e-02,  1.07046776e-02, -2.57816222e-02],\n",
       "        [-1.66898351e-02,  8.72420520e-03, -2.33787131e-02],\n",
       "        [-2.10164078e-02,  1.08734844e-02, -2.85089854e-02],\n",
       "        [-6.45379722e-03,  1.09480200e-02, -1.41350143e-02],\n",
       "        [-1.67942122e-02,  1.30525744e-02, -2.54635625e-02],\n",
       "        [-4.67504282e-03,  3.31849465e-03, -8.57875030e-03],\n",
       "        [-2.31977496e-02,  2.90613733e-02, -3.60298678e-02],\n",
       "        [-1.37788858e-02,  5.96348615e-03, -2.02221870e-02],\n",
       "        [-9.84353479e-03, -8.64276662e-03, -1.10815540e-02],\n",
       "        [-6.05439954e-03,  5.84402075e-03, -1.07930899e-02],\n",
       "        [-1.35218408e-02,  2.28218567e-02, -2.41995081e-02],\n",
       "        [-1.63693465e-02,  1.16625717e-02, -2.37385202e-02],\n",
       "        [-1.60675291e-02,  2.45253108e-02, -2.81308927e-02],\n",
       "        [-2.35284306e-02,  1.39143029e-02, -3.20341736e-02],\n",
       "        [-2.13305801e-02,  1.86981037e-02, -3.21146026e-02],\n",
       "        [-1.21544702e-02,  9.66200326e-03, -2.00426485e-02],\n",
       "        [-2.36308165e-02,  1.20267104e-02, -3.32737602e-02],\n",
       "        [-8.17133207e-03,  3.40481801e-03, -1.30320610e-02],\n",
       "        [-2.22107656e-02,  2.48071384e-02, -3.41774411e-02]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(64, 3), dtype=float32, numpy=\n",
       " array([[-0.0018511 ,  0.01112687, -0.02537465],\n",
       "        [ 0.00200702,  0.01103388, -0.00379362],\n",
       "        [-0.00128268,  0.00931226, -0.02235153],\n",
       "        [ 0.00292578,  0.00733007, -0.03332894],\n",
       "        [ 0.0073349 ,  0.0158429 , -0.03733466],\n",
       "        [ 0.01382432,  0.01073901, -0.02469375],\n",
       "        [ 0.00363846,  0.01940751, -0.01877679],\n",
       "        [ 0.01716562,  0.01209708, -0.02761932],\n",
       "        [ 0.0023883 ,  0.01497722, -0.03108474],\n",
       "        [ 0.01451365,  0.0146016 , -0.03964937],\n",
       "        [-0.00229616,  0.01773586, -0.02692955],\n",
       "        [ 0.00881314,  0.01214697, -0.03134053],\n",
       "        [ 0.010038  ,  0.01915471, -0.01181442],\n",
       "        [ 0.02494924,  0.00141878, -0.0229605 ],\n",
       "        [ 0.00586812,  0.01477418, -0.03577682],\n",
       "        [ 0.00963701,  0.00969552, -0.02376619],\n",
       "        [ 0.01047162,  0.01178252, -0.01068325],\n",
       "        [ 0.01704125,  0.00617275, -0.02987628],\n",
       "        [ 0.00889703,  0.01307175, -0.03383235],\n",
       "        [-0.00245684,  0.02116525, -0.02101709],\n",
       "        [-0.0073491 ,  0.01580541, -0.01747159],\n",
       "        [ 0.01067473,  0.0101822 , -0.03782289],\n",
       "        [ 0.00705833,  0.0182388 , -0.00881787],\n",
       "        [ 0.01440165,  0.00840298, -0.02607201],\n",
       "        [ 0.00819511,  0.00849059, -0.02228115],\n",
       "        [ 0.01002215,  0.01412449, -0.01865919],\n",
       "        [ 0.0079038 ,  0.01446382, -0.02645827],\n",
       "        [-0.00361611,  0.00968594, -0.03020501],\n",
       "        [ 0.00895942,  0.01608896, -0.01523027],\n",
       "        [ 0.01101437,  0.0098111 , -0.00830457],\n",
       "        [ 0.01302276,  0.00834719, -0.02240065],\n",
       "        [ 0.01617402,  0.01102191, -0.01597644],\n",
       "        [ 0.02152551,  0.00661077, -0.03611987],\n",
       "        [ 0.00814477,  0.01406156, -0.03081713],\n",
       "        [ 0.00101482,  0.01723489, -0.03358651],\n",
       "        [ 0.00070435,  0.01691953, -0.04069715],\n",
       "        [ 0.02298784,  0.00413551, -0.0489515 ],\n",
       "        [ 0.00987949,  0.00779945, -0.02347382],\n",
       "        [ 0.01246385,  0.01469655, -0.01404798],\n",
       "        [ 0.01622807,  0.00810071, -0.02694322],\n",
       "        [-0.00228284,  0.01429545, -0.04644673],\n",
       "        [ 0.02135123,  0.0103806 , -0.00946965],\n",
       "        [ 0.02160958,  0.0078068 , -0.02156139],\n",
       "        [ 0.01259751,  0.0086456 , -0.04406613],\n",
       "        [ 0.00704249,  0.01372265, -0.02350427],\n",
       "        [ 0.00848339,  0.01370857, -0.03117609],\n",
       "        [ 0.00505193,  0.01078534, -0.02900835],\n",
       "        [ 0.00432016,  0.0095329 , -0.03509405],\n",
       "        [ 0.0165753 ,  0.01322179, -0.01320646],\n",
       "        [ 0.01133568,  0.0116736 , -0.02877385],\n",
       "        [ 0.00618127,  0.01066853, -0.01072482],\n",
       "        [ 0.02294404, -0.00074735, -0.03185588],\n",
       "        [ 0.00552412,  0.01545806, -0.026507  ],\n",
       "        [-0.00961858,  0.01995821, -0.02428105],\n",
       "        [ 0.00809363,  0.00945022, -0.01206511],\n",
       "        [ 0.02310967,  0.00311974, -0.01886674],\n",
       "        [ 0.00821747,  0.00842652, -0.02716274],\n",
       "        [ 0.02484471,  0.00573563, -0.02357781],\n",
       "        [ 0.00594872,  0.00792846, -0.0380145 ],\n",
       "        [ 0.01496139,  0.00979072, -0.03438626],\n",
       "        [ 0.01175571,  0.01543305, -0.02329537],\n",
       "        [ 0.00735962,  0.01667381, -0.04163007],\n",
       "        [ 0.00543012,  0.01417638, -0.01753921],\n",
       "        [ 0.0197933 ,  0.00351055, -0.03251893]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(64, 3), dtype=float32, numpy=\n",
       " array([[-5.81451915e-02, -2.94608604e-02, -5.35388291e-03],\n",
       "        [-8.56350362e-03,  2.80150585e-02,  9.37383622e-02],\n",
       "        [-4.27900180e-02, -3.20777036e-02,  3.27765122e-02],\n",
       "        [-1.80990789e-02, -7.63657540e-02, -4.70922887e-03],\n",
       "        [ 5.14225475e-02, -4.44664992e-02, -8.75355750e-02],\n",
       "        [-1.33910820e-01,  1.53320683e-02,  5.14462478e-02],\n",
       "        [ 1.08024016e-01, -9.87941399e-02, -4.10647206e-02],\n",
       "        [ 6.52646422e-02, -7.86576718e-02,  3.17011327e-02],\n",
       "        [-5.80820106e-02,  7.03476137e-03, -7.68832490e-03],\n",
       "        [-3.23491134e-02, -1.19377844e-01,  1.46450149e-02],\n",
       "        [-1.16915435e-01, -4.41053845e-02,  2.49288622e-02],\n",
       "        [ 4.56514396e-02, -7.76954144e-02,  1.98114030e-02],\n",
       "        [ 5.89995235e-02, -4.10132855e-02, -8.10175296e-03],\n",
       "        [-2.78167911e-02, -4.57513407e-02, -5.57698160e-02],\n",
       "        [ 7.24666640e-02, -1.16000280e-01, -9.14428732e-04],\n",
       "        [ 4.04297411e-02, -6.86835423e-02,  3.33170518e-02],\n",
       "        [-1.17012078e-03, -4.61337566e-02, -3.84317786e-02],\n",
       "        [ 1.52126886e-02, -9.32353437e-02, -4.63942774e-02],\n",
       "        [ 5.51607013e-02, -1.09295540e-01,  2.83765551e-02],\n",
       "        [-1.10150598e-01, -4.97578718e-02, -6.21714331e-02],\n",
       "        [ 1.34273078e-02, -5.30201383e-02,  4.38745655e-02],\n",
       "        [-1.98146701e-02, -4.88546044e-02,  8.53231549e-03],\n",
       "        [-6.48874650e-03, -6.80772364e-02,  4.74453118e-05],\n",
       "        [ 5.99216670e-02,  5.48243662e-03,  1.59923378e-02],\n",
       "        [ 1.83745497e-03, -2.19249185e-02, -2.40930207e-02],\n",
       "        [-3.96530069e-02, -5.85212894e-02,  2.88865082e-02],\n",
       "        [-1.65476445e-02, -7.67587349e-02, -1.34286717e-01],\n",
       "        [-6.79228455e-02, -1.82000566e-02, -2.98439320e-02],\n",
       "        [ 4.14006859e-02, -4.43750136e-02,  1.84223875e-02],\n",
       "        [ 1.51848393e-02, -2.01296341e-02,  3.73104028e-02],\n",
       "        [ 3.67877930e-02, -6.47341311e-02, -4.04120944e-02],\n",
       "        [-1.54306442e-02, -4.97970767e-02,  9.77988448e-03],\n",
       "        [-1.01733664e-02, -1.57848019e-02,  8.23177025e-02],\n",
       "        [ 4.41416539e-02, -3.81340273e-02,  7.78668211e-04],\n",
       "        [-2.00701617e-02, -9.49634761e-02, -9.35695507e-03],\n",
       "        [ 7.99739733e-03, -1.18306115e-01,  3.20823491e-02],\n",
       "        [-1.39607638e-02, -6.20380305e-02,  1.62990484e-02],\n",
       "        [-4.16310355e-02, -9.02161896e-02, -5.16390130e-02],\n",
       "        [ 6.86714426e-03, -7.49209747e-02,  4.30922955e-03],\n",
       "        [ 5.36571629e-02, -1.20644689e-01, -1.23950187e-02],\n",
       "        [-1.00898348e-01, -6.76694140e-02, -2.05802638e-02],\n",
       "        [ 1.50194382e-02,  1.90063193e-02,  5.10070994e-02],\n",
       "        [-1.60200708e-02, -8.49195421e-02,  6.42176112e-03],\n",
       "        [-2.01308001e-02, -5.09048440e-02,  2.49930024e-02],\n",
       "        [-5.40420189e-02, -1.70103693e-03,  5.77662401e-02],\n",
       "        [-6.87945560e-02, -3.65693346e-02,  3.19474824e-02],\n",
       "        [-7.93199986e-02, -1.30042518e-02,  3.39968577e-02],\n",
       "        [-5.30001372e-02, -2.29107365e-02, -8.34647417e-02],\n",
       "        [ 3.30602787e-02, -5.23412302e-02, -5.12744859e-02],\n",
       "        [-5.04454738e-03, -5.20187151e-03,  2.06614845e-02],\n",
       "        [ 8.32916647e-02, -2.12150794e-02,  1.84293874e-02],\n",
       "        [ 8.62023458e-02, -2.19980329e-02, -5.08527309e-02],\n",
       "        [ 4.37917188e-02, -3.09896329e-03,  4.35555726e-02],\n",
       "        [-3.97984311e-02, -8.77466202e-02,  6.38705194e-02],\n",
       "        [ 2.35338490e-02,  2.24117679e-03, -2.98943780e-02],\n",
       "        [ 9.51822177e-02, -1.04835518e-01,  2.01642103e-02],\n",
       "        [-3.42722572e-02, -4.22625430e-02, -3.26323994e-02],\n",
       "        [-4.51235138e-02, -7.99260139e-02, -4.66024876e-02],\n",
       "        [-7.43243545e-02,  9.00556799e-03, -3.57693732e-02],\n",
       "        [-5.57721630e-02, -3.22919637e-02,  4.93211634e-02],\n",
       "        [-2.99943821e-03, -6.03490695e-02, -3.13983373e-02],\n",
       "        [-3.38920653e-02, -1.31321233e-02,  2.75362264e-02],\n",
       "        [-1.00444525e-01,  3.85990292e-02, -6.66645020e-02],\n",
       "        [-1.81224756e-02, -8.22052062e-02, -2.44160630e-02]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(64, 3), dtype=float32, numpy=\n",
       " array([[-0.02309517, -0.01951064, -0.03575448],\n",
       "        [ 0.06900033,  0.14541711, -0.0296631 ],\n",
       "        [ 0.01827559,  0.12694359,  0.03130323],\n",
       "        [ 0.0076467 ,  0.11359628, -0.02518263],\n",
       "        [-0.09653318,  0.05879879, -0.06156722],\n",
       "        [ 0.0018962 ,  0.10095777, -0.01914315],\n",
       "        [-0.03051189,  0.10574261,  0.00513282],\n",
       "        [ 0.06551404, -0.02152822, -0.05775876],\n",
       "        [ 0.07494659,  0.11461212, -0.14329576],\n",
       "        [-0.00477549,  0.09352645, -0.00231798],\n",
       "        [ 0.02563855,  0.08976363,  0.00350787],\n",
       "        [-0.04085108,  0.08133865, -0.00055993],\n",
       "        [ 0.00311645,  0.04274461, -0.02755087],\n",
       "        [ 0.06172935,  0.15240294, -0.05765316],\n",
       "        [ 0.00746737,  0.02408472, -0.12257001],\n",
       "        [ 0.01953323,  0.05405311, -0.02503945],\n",
       "        [-0.00205157,  0.06664132, -0.1003636 ],\n",
       "        [ 0.03299918,  0.10907219, -0.00064373],\n",
       "        [-0.02404642,  0.06403057, -0.07777803],\n",
       "        [ 0.02540415,  0.05351209, -0.06698103],\n",
       "        [ 0.02012846,  0.09783866,  0.00385715],\n",
       "        [ 0.09158038,  0.08372216, -0.07392113],\n",
       "        [ 0.03874345,  0.11804207,  0.0036922 ],\n",
       "        [ 0.07752463,  0.06619671, -0.08193846],\n",
       "        [ 0.10846764,  0.07611447, -0.1038198 ],\n",
       "        [ 0.00871676,  0.10053881,  0.03825255],\n",
       "        [-0.000537  , -0.00611707,  0.00403487],\n",
       "        [-0.01698075,  0.08941929,  0.10399971],\n",
       "        [-0.03552585, -0.00877051,  0.02243495],\n",
       "        [ 0.0986031 ,  0.15164809, -0.03956426],\n",
       "        [ 0.02736624,  0.07515002, -0.05605753],\n",
       "        [ 0.0596728 ,  0.13333601,  0.04453712],\n",
       "        [ 0.05669619,  0.00548917,  0.01825251],\n",
       "        [-0.02517984,  0.11137383, -0.07565656],\n",
       "        [-0.01767293,  0.01024472, -0.08486571],\n",
       "        [-0.05338834,  0.03391919, -0.06552193],\n",
       "        [-0.06192818,  0.04378558,  0.02467141],\n",
       "        [-0.0758203 ,  0.01435234, -0.03487362],\n",
       "        [ 0.01761807,  0.03260539, -0.03324319],\n",
       "        [-0.12686455,  0.08596987, -0.00037726],\n",
       "        [-0.01525079,  0.07976268,  0.03867699],\n",
       "        [ 0.0886879 ,  0.12582675, -0.08092175],\n",
       "        [ 0.05268582,  0.11565398, -0.07245754],\n",
       "        [ 0.04478638,  0.04260293, -0.07894865],\n",
       "        [-0.0262071 ,  0.17286083,  0.02085668],\n",
       "        [ 0.00448259,  0.04676205, -0.01632858],\n",
       "        [ 0.02279859,  0.10819011,  0.0013388 ],\n",
       "        [ 0.02684118,  0.04125367,  0.002388  ],\n",
       "        [ 0.02505063,  0.03417218, -0.0108435 ],\n",
       "        [ 0.01062325,  0.14651814,  0.05709598],\n",
       "        [ 0.06140323,  0.02042906, -0.10673282],\n",
       "        [ 0.02075408,  0.08394181, -0.0386612 ],\n",
       "        [ 0.02637137,  0.04329728, -0.02415374],\n",
       "        [ 0.02111975,  0.13124892,  0.03879795],\n",
       "        [ 0.10151383,  0.08097006, -0.06482222],\n",
       "        [-0.00703931,  0.01964236, -0.00789726],\n",
       "        [ 0.04751512,  0.17888641, -0.09473785],\n",
       "        [ 0.10732855,  0.00934492, -0.03597455],\n",
       "        [ 0.02114088,  0.10376354, -0.0157245 ],\n",
       "        [ 0.08218475,  0.12035685,  0.00063857],\n",
       "        [ 0.09455216,  0.00820919, -0.01454678],\n",
       "        [ 0.0439204 ,  0.08256375, -0.04700107],\n",
       "        [ 0.12311266,  0.06827836, -0.03940707],\n",
       "        [-0.02847466,  0.03733611,  0.02999514]], dtype=float32)>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vrnn(input_1_data, training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research env",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
